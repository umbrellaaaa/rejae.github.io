---
layout:     post
title:      work sunday
subtitle:   
date:       2020-1-12
author:     RJ
header-img: 
catalog: true
tags:
    - job

---
<p id = "build"></p>
---

## Faspell.py

Faspell是iqiyi这个项目的核心，从main角度出发：

```python
    spell_checker = SpellChecker()
    args = parse_args()
    if args.mode == 's':  # command line mode
    elif args.mode == 'f':  # file mode
    elif args.mode == 'e':  # experiment mode
        
        if args.train:
        else:
```
核心类：spell_checker

初始化了mask_lm.py中的MaskedLM核心类和 Faspell中的Filter类

## 单独运行mask_lm.py，输入待纠正的句子及参数batch=2:    res = lm.find_topn_candidates(['。国际电台苦名丰持人。'], 2)

得到结果：
```
[

[('。', 0.9719299674034119), ('为', 0.0023953726049512625), ('在', 0.0017006774432957172), ('国', 0.0012299128575250506), ('，', 0.0011058669770136476)], 

[('国', 0.9999924898147583), ('是', 2.6962738957081456e-06), ('时', 7.9861024460115e-07), ('当', 4.4179515157338756e-07), ('为', 3.6955142945771513e-07)],

[('际', 0.9997978806495667), ('際', 8.713549323147163e-05), ('国', 5.577431511483155e-05), ('international', 2.1784724594908766e-05), ('名', 9.248366950487252e-06)],

[('电', 0.9984951019287109), ('广', 0.0006644673994742334), ('radio', 0.00014615342661272734), ('一', 8.779176278039813e-05), ('听', 8.76405174494721e-05)], 

[('台', 0.9999879598617554), ('名', 6.9566790443786886e-06), ('视', 2.837861984517076e-06), ('radio', 3.7333077784751367e-07), ('道', 3.674671518183459e-07)], 

[('著', 0.2728172540664673), ('又', 0.17619529366493225), ('一', 0.08877086639404297), ('知', 0.0426778718829155), ('，', 0.042287275195121765)], 

[('名', 0.9994926452636719), ('称', 8.226370118791237e-05), ('台', 7.597395597258583e-05), ('号', 2.557618608989287e-05), ('级', 2.0354198568384163e-05)], 

[('主', 0.9937467575073242), ('女', 0.0016344449250027537), ('支', 0.0008364854729734361), ('坚', 0.0002798374625854194), ('男', 0.00027676354511640966)],

[('持', 0.99897301197052), ('播', 0.00022466153313871473), ('讲', 0.00012336819781921804), ('语', 4.2864852730417624e-05), ('目', 3.561308767530136e-05)], 

[('人', 0.9999940395355225), ('师', 3.3910075671883533e-06), ('者', 5.397726567935024e-07), ('持', 4.82236771404132e-07), ('员', 2.240535792452647e-07)],

[('。', 0.9995909333229065), ('，', 0.00023216016415972263), ('；', 3.5312888940097764e-05), (',', 1.5493655155296437e-05), ('的', 6.440294782805722e-06)]

]
```

这是只用bert的mask模型得到的结果，感觉纠错还行，纯根据语言模型纠错。

## pycorrector

没想到，这个repository这么大，可以说是覆盖了绝大部分纠错的模型，包括：
- bert
- conv_seq2seq
- rnn_attention
- seq2seq_attention
- transformer