---
layout:     post
title:      workday26
subtitle:   
date:       2020-1-20
author:     RJ
header-img: 
catalog: true
tags:
    - job

---
<p id = "build"></p>
---

## 预测中有繁体字的问题

若候选top1与原字相同，不改变该字，即需要将过滤直线定死。

same 情况下:

![](https://raw.githubusercontent.com/rejae/rejae.github.io/master/img/20200119163008.png)

similarity =(5 - 5*confidence)/2

即要求confidence很高，但是这是不可能的。

于是决绝了繁体字的问题。

同时也修正了检错率：

对应位置检错共：7502处

检错率： 7502/20622=0.36378624769663465


## 调节filter
```
    {
        "original_sentence": "为了规避三司限城市明显过剩的市场风险",
        "corrected_sentence": "为了规避三三线城市明显过应的市场风险",
        "num_errors": 3,
        "errors": [
            {
                "error_position": 5,
                "original": "司",
                "corrected_to": "三",
                "candidates": {
                    "三": 0.4736703038215637,
                    "四": 0.22112873196601868,
                    "二": 0.11617789417505264,
                    "五": 0.08753466606140137,
                    "省": 0.016652248799800873
                },
                "confidence": 0.4736703038215637,
                "similarity": 0.44666666666666677,
                "sentence_len": 18
            }
```
加大在diff的情况下的similarity权重

调试发现：在rank=0的时候出现了error，那么程序将执行：
```python
if error:
    res.append(error)
    char = error["corrected_to"]
    sentence += char
    continue

sentence += char
```
即对其他的rank=1,2,3... 将跳过

即在候选top1与原字不同的情况下，只根据confidence候选为top1修改。其他的候选直接pass，这样显然有些不合理。

尝试取所有候选，根据confidence和similarity计算一个带权值进行sort取top1。这样既能用到confidence，也能用到similarity信息。

```python
#rank error by conf and simi
if error_rank_by_con_sim!=[]:

    rank_dict = dict()
    for idx,item in enumerate(error_rank_by_con_sim):
        rank_dict[str(idx)]=item['confidence']+3*item["similarity"]
    sorted_id = int(sorted(rank_dict.items(),key= lambda item:item[1])[-1][0])
    error = error_rank_by_con_sim[sorted_id]
    print(sorted_id,'xxxxxx',error)
```

```
origin：为了规避三司限城市明显过剩的市场风险	
INFO:root:current sentence is corrected to 为了规避三四线城市明显过应的市场风险
```
可以看到“司”字被正确替换为“四”，而不是“三”。 但与此同时“剩”居然被替换了成“应”字。

查看打印记录发现：
```
INFO:root:剩--> 应 (con=0.4477047920227051, sim=0.4666666666666667, on_top_difference=True)
continue
INFO:root:spell checking on rank=1
INFO:root:剩 --> <PASS-剩> (con=0.33401036262512207, sim=null, on_top_difference=True)
```
剩字的sim为null，即其发音存在问题。查看char_meta文件得到：

U+5269	剩	sheng4;sing6,zing6;ING;JOU;null	⿰⿻⿱丿一丨丿㇏⿰③⿺乚丿丨亅


## 新的situation
在项目原实现中：当origin字与candidate中按confidence的top1相同的时候，return error是None,

以上剩字出现的情形是： 按top1排序的candidate不是原字，但是原字排在top2, 在这种情形下，top2会因为判断if cand_token != sentence[j]，从而返回None, 根本没有结合similarity，所以导致出现以上情形。（error_rank_by_con_sim没有 “剩”）

简单的修改： if cand_token != sentence[j] and rank！=0: 应该可行

得到结果：
```
为了规避三四限城市明显过剩的市场风险
INFO:root:current sentence is corrected to 为了规避三四限城市明显过剩的市场风险
```
但是这里，线字又出现了问题

具体的：
```
INFO:root:限--> 线 (con=0.3266430199146271, sim=0.6, on_top_difference=True)
continue
INFO:root:spell checking on rank=1
True
INFO:root:限--> 限 (con=0.16538123786449432, sim=1.0, on_top_difference=True)
```
因为限字被加入到了候选，其发音完全一样，导致其排名很高。具体的排名方式为：

rank_dict[str(idx)]=item['confidence']+3*item["similarity"]

这里出现一个问题，限字和线字的发音：
```
U+9650	限	xian4;haan6;HAN;GEN,KAN;hạn

U+7EBF	线	xian4;sin3
```
在char_meta.txt文件中去掉其他语言的发音 or 停用其他发音

在char_sim.py中，214 row: break 循环

得到结果：INFO:root:current sentence is corrected to 为了规避三四限城市明显过剩的市场风险

**以上操作，看似对单个例子进行调试，但是对全局调试也存在一定的意义**

测试结果： 13050/20622 = 0.632819319173698

检错率有了成倍显著的提升！！！

##　总结一下修改

1. 在候选top1与原字不同的情况下，只根据confidence候选为top1直接修改，其他的候选直接pass。-->>根据conf and sim 排序top1修改
2. similarity计算，去掉其他粤语、日语等语言发音，只根据中文发音
3. 当origin字与candidate中按confidence的top1相同的时候，pass不修改。但是当origin字与候选非top1相同时还是要进入error_list
    if cand_token != sentence[j] and rank！=0:

4. 过滤线的选择，对于候选top1与原字相同，过滤非常严格；对于不同，不用过滤都可以，因为会按conf以及simi加权倒排序。

## tackle_n_gram_bias

解决连续N个字纠错可能引入的错误，仅纠错一个字

## 阅读

[深度学习下，中文分词是否还有必要？](https://mp.weixin.qq.com/s/w8TIkIatKi7XNDUFivhgng)



为了规避三三限城市明显过剩的市场风险
为了规避三三线城市明显过应的市场风险