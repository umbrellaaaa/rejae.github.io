---
layout:     post
title:      workday12
subtitle:   
date:       2019-12-31
author:     RJ
header-img: 
catalog: true
tags:
    - Job


---
<p id = "build"></p>
---



## 指定GPU训练

with tf.device('/gpu:2'):

import os

os.environ['CUDA_VISIBLE_DEVICES']='2'

os.environ['CUDA_VISIBLE_DEVICES']='2,3'

CUDA_VISIBLE_DEVICES=2 python train.py



## 1.清洗语料为统一格式到train.tsv训练文件中

![](https://raw.githubusercontent.com/rejae/rejae.github.io/master/img/20191231dataclear1.png)

将各个txt文件，按格式汇总到train.tsv文件中，取train.tsv以外的ai_shell_test.txt文件为Test数据。

train.tsv共计1,106,100条数据，大小为150M

ai_shell_test.txt数据共7176条数据，大小为1.2M

## 2.baseline训练
在保持 warm_up启动，gelu激活，batch_size=16, epoch=10 的情况下：

此次训练进行FFNN的对比实验，查看在每个block中使用FFNN和仅最后一个使用FFNN的效果。




## 3.研究decoder部分
一般的，encoder进行特征抽取和编码后，接一个全连接映射到label大小的空间上，就得到了预测label.

我对decoder不太熟悉，今天特此学习一下。
```python
    def decode(self, ys, memory, src_masks, training=True):
        '''
        memory: encoder outputs. (N, T1, d_model)
        src_masks: (N, T1)

        Returns
        logits: (N, T2, V). float32.
        y_hat: (N, T2). int32
        y: (N, T2). int32
        sents2: (N,). string.
        '''
        with tf.variable_scope("decoder", reuse=tf.AUTO_REUSE):
            decoder_inputs, y, seqlens, sents2 = ys

            # tgt_masks
            tgt_masks = tf.math.equal(decoder_inputs, 0)  # (N, T2)

            # embedding
            dec = tf.nn.embedding_lookup(self.embeddings, decoder_inputs)  # (N, T2, d_model)
            dec *= self.hp.d_model ** 0.5  # scale

            dec += positional_encoding(dec, self.hp.maxlen2)
            dec = tf.layers.dropout(dec, self.hp.dropout_rate, training=training)

            # Blocks
            for i in range(self.hp.num_blocks):
                with tf.variable_scope("num_blocks_{}".format(i), reuse=tf.AUTO_REUSE):
                    # Masked self-attention (Note that causality is True at this time)
                    dec = multihead_attention(queries=dec,
                                              keys=dec,
                                              values=dec,
                                              key_masks=tgt_masks,
                                              num_heads=self.hp.num_heads,
                                              dropout_rate=self.hp.dropout_rate,
                                              training=training,
                                              causality=True,
                                              scope="self_attention")

                    # Vanilla attention
                    dec = multihead_attention(queries=dec,
                                              keys=memory,
                                              values=memory,
                                              key_masks=src_masks,
                                              num_heads=self.hp.num_heads,
                                              dropout_rate=self.hp.dropout_rate,
                                              training=training,
                                              causality=False,
                                              scope="vanilla_attention")
                    ### Feed Forward
                    dec = ff(dec, num_units=[self.hp.d_ff, self.hp.d_model])

        # Final linear projection (embedding weights are shared)
        weights = tf.transpose(self.embeddings) # (d_model, vocab_size)
        logits = tf.einsum('ntd,dk->ntk', dec, weights) # (N, T2, vocab_size)
        y_hat = tf.to_int32(tf.argmax(logits, axis=-1))

        return logits, y_hat, y, sents2
```

正如Encoder-Decoder图中所说，decoder部分先有一个self-attention，然后再接一个encoder-decoder-attention.

所以在encoder-decoder-attention.中，queries是由dec的self-attention作为输入，而key,value都是encoder的输出结果。

如此一来，queries与encoder的output发生关系。但是这里的queries又代表了什么呢？

经过查阅资料，encoder-decoder结构确实是teacher forcing 模式，将目标序列加入到decoder进行纠正学习。

此时

encoder输入格式：  pny_list[i],  < /s > , padding ...

而decoder输入格式：  < s >, han_list[i]  , padding ...

而项目代码使用的是dense layer映射输出到lable空间上。

分析二者的实现方式，注意到， encoder-decoder结构，一定要使用label作为输入，进行teacher forcing纠正操作。而现实项目的Test环节中，我们从语音到拼音再到汉字是没有Label作为输入的。

此时Test采用预测到的前面的字作为输入，此过程类似于CharRNN语言模型。

从理论上分析，encoder-decoder结构有自回归语言模型的效果，柑橘上效果会更好，但是由于在训练过程中teacher forcing的引入，与Test时，没有Label作纠正，可能会带来一定的不一致性。

参考问题：
[is-teacher-forcing-more-accurate-than-using-actual-model-output-or-just-faster](https://stats.stackexchange.com/questions/259333/is-teacher-forcing-more-accurate-than-using-actual-model-output-or-just-faster)


Unfortunately, this procedure[teacher forcing] can result in problems in generation as small prediction error compound in the conditioning context. 

This can lead to poor prediction performance as the RNN’s conditioning context (the sequence of previously generated samples) diverge from sequences seen during training


## 模型训练

模型已经训练了一天了，对比两种FFNN实现，发现多个FFNN效果明显更好，就当前的4个Epoch而言：

单个FFNN：
```
epoch: 1 : average loss =  1.607837822291023 average acc =  0.9081820209222166
epoch: 2 : average loss =  1.4502084983086483 average acc =  0.9439162303854729
epoch: 3 : average loss =  1.4242003758483965 average acc =  0.9507446194030981
epoch: 4 : average loss =  1.4104817117445707 average acc =  0.9543785420725818

```

多个FFNN：
```
epoch: 1 : average loss =  1.58392153555198 average acc =  0.9090912181610195
epoch: 2 : average loss =  1.404457000279954 average acc =  0.9524611907196994
epoch: 3 : average loss =  1.364144632988789 average acc =  0.9628293010589831
epoch: 4 : average loss =  1.3410292862880162 average acc =  0.9686572444693973
```

显然多个FFNN效果更好。
