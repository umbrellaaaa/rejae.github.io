---
layout:     post
title:      workday20
subtitle:   
date:       2020-1-13
author:     RJ
header-img: 
catalog: true
tags:
    - job

---
<p id = "build"></p>
---

## 回顾
昨天在家里调试了一下pycorrector，此项目比较大，对中文纠错的研究也比较全面，代码里研究的模型包括：

- bert
- seq2seq_attention
- conv_seq2seq
- rnn_attention
- transformer

该项目默认使用kenlm模型：

language_model_path = os.path.join(USER_DATA_DIR, 'zh_giga.no_cna_cmn.prune01244.klm')
```python
    pre_trained_language_models = {
        #百度提供语言模型 2.95GB
        'zh_giga.no_cna_cmn.prune01244.klm': 'https://deepspeech.bj.bcebos.com/zh_lm/zh_giga.no_cna_cmn.prune01244.klm',
        #人民日报训练语言模型 20MB
        'people_chars_lm.klm': 'https://www.borntowin.cn/mm/emb_models/people_chars_lm.klm'
    }
```
[kenlm训练 及 使用](https://blog.csdn.net/weixin_34082177/article/details/94631984)

##　使用生成的错误语音数据调试pycorrector模型

```
('以后你是男孩子', [])
('来掉拿有买路湖骑车了', [])
('看看我的是行表', [['省表', '行表', 5, 7]])
('我老婆之大笨蛋', [['知大', '之大', 3, 5]])
('我说你明天早上七点叫我机床', [['急床', '机床', 11, 13]])
('再给我想个笑法好吗', [])
('播放歌曲最选民如风', [['最炫民', '最选民', 4, 7]])
('退税当前播放模式', [['退说', '退税', 0, 2]])
('我家的狗张什么零字', [])
('英文给你一个京西', [])
('唱一首老人海', [])
('对练英为听说有帮助的歌请推荐几首谢谢', [['听率', '听说', 4, 6]])
('你会不会说四厂话', [])
('给刘建峰打电话', [])
```

发现检错召回率很低，2000个句子，未检测到的句子就有1101条。而且检出的正确率也很低，有很多纠错也不正确。

分析一下，语音识别会出现很多生活化的词汇，不拘泥语法规范，无领域约束，与书面表达有一定的差距，而语音识别出错而得到的错误文本进一步加大了待纠错的句子的错误。

常规的N-gram语言模型的训练数据通常来自于文本语料，少有具备规模的语音数据来训练，所以传统的语言模型得到很差的结果也是情理之中的。

pycorrector在语言识别的表现很差，也是正常的，因为它默认使用的是kenlm语言模型，是传统的5-gram模型。

pycorrector中除了默认的kenlm模型外，还有5个深度学习模型可以使用。

## 调试bert模型：
首先pycorrector中提供的bert finetune语料是：
- 人名日报2014版数据（网盘链接:https://pan.baidu.com/s/1971a5XLQsIpL0zL0zxuK2A  密码:uc11）101MB

使用该语料，finetune 3 个epoch得到提供的finetune模型

- 训练时长：3块p40GPU训练3轮，超过24小时。

其中错误检测模块设定阈值为0.1：
```python
    def detect(self, sentence):
        """
        句子改错
        :param sentence: 句子文本
        :param threshold: 阈值
        :return: list[list], [error_word, begin_pos, end_pos, error_type]
        """
        maybe_errors = []
        for prob, f in self.predict_token_prob(sentence):
            logger.debug('prob:%s, token:%s, idx:%s' % (prob, f.token, f.id))
            if prob < self.threshold:
                maybe_errors.append([f.token, f.id, f.id + 1, ErrorType.char])
        return maybe_errors
```

第一次测试，取10个错误句子测试效果，得到结果：
```
["original sentence:以后你是男孩子 => correct sentence:('以为你是男孩子', [['后', '为', 1, 2]])",
 "original sentence:来掉拿有买路湖骑车了 => correct sentence:('[UNK]掉拿有买路湖骑车了', [['来', '[UNK]', 0, 1]])",
 "original sentence:看看我的是省表 => correct sentence:('请看到的各列表', [['看', '请', 0, 1], ['我', '到', 2, 3], ['是', '各', 4, 5], ['省', '列', 5, 6]])",
 "original sentence:我老婆知大笨蛋 => correct sentence:('[UNK]老婆知大笨蛋', [['我', '[UNK]', 0, 1]])",
 "original sentence:我说你明天早上七点叫我急床 => correct sentence:('你说你明天早上七点叫我起床', [['我', '你', 0, 1], ['急', '起', 11, 12]])",
 "original sentence:再给我想个笑法好吗 => correct sentence:('请给我一个说法好。', [['再', '请', 0, 1], ['想', '一', 3, 4], ['笑', '说', 5, 6], ['吗', '。', 8, 9]])",
 "original sentence:播放歌曲最炫民如风 => correct sentence:('播放歌曲最炫民如风', [])",
 "original sentence:退说当前播放模式 => correct sentence:('解析当前播放模式', [['退', '解', 0, 1], ['说', '析', 1, 2]])",
 "original sentence:我家的狗张什么零字 => correct sentence:('你家的狗是什么名字', [['我', '你', 0, 1], ['张', '是', 4, 5], ['零', '名', 7, 8]])",
 "original sentence:英文给你一个京西 => correct sentence:('英文给你一个京西', [])"]
```

首先，这些错误数据时以前的语音模型和语言模型生成的数据，有些数据错误太大，以至于人都难以很好的猜测出正确句子，所以，挑选一些例子来测试很有必要。

由于之前得到了两份不同的语音测试数据，上面的句子更贴近生活化，难度较大，错误也更复杂，所以使用第二份数据，即AI_shell的数据测试：
```
["corr:甚至出现交易几乎停滞的情况 =>error:甚至出现交易几乎停之的情况 => rectify:('甚至出现交易几乎了之的情况', [['停', '了', 8, 9]])",
 "corr:一二线城市虽然也处于调整中 =>error:一二线城市虽然也处于调整中 => rectify:('而二线楼市虽然也处于调整中', [['一', '而', 0, 1], ['城', '楼', 3, 4]])",
 "corr:但因为聚集了过多公共资源 =>error:大因为聚集了过多公共思源 => rectify:('正因为聚集了过多公共思源', [['大', '正', 0, 1]])",
 "corr:为了规避三四线城市明显过剩的市场风险 =>error:为了规避三司限城市明显过剩的市场风险 => rectify:('为了规避三司限城市明显过剩的市场风险', [])",
 "corr:标杆房企必然调整市场战略 =>error:标港房企必然条长市场的略 => rectify:('香港房企必然成长市场策略', [['标', '香', 0, 1], ['条', '成', 6, 7], ['的', '策', 10, 11]])",
 "corr:因此土地储备至关重要 =>error:因此土地储备之观重要 => rectify:('因此土地储备之观重要', [])",
 "corr:中原地产首席分析师张大伟说 =>error:中原地产手新分析师张大伟说 => rectify:('中原地产手新分析师张大伟说', [])",
 "corr:一线城市土地供应量减少 =>error:一线城市土地供应量减少 => rectify:('一线城市土地供应量减少', [])",
 "corr:也助推了土地市场的火爆 =>error:也助推乐土地市场的火爆 => rectify:('为助推乐土地市场的火爆', [['也', '为', 0, 1]])",
 "corr:北京仅新增住宅土地供应十宗 =>error:被精景新生住宅土地供应石松 => rectify:('[UNK]精景新生住宅土地供应石松', [['被', '[UNK]', 0, 1]])"]
```

同样，bert模型也有detect和correct两个模块，分别负责检错和纠错。其中检错模块设定的默认阈值是0.1，如果概率小于0.1，那么该字将会被添加到maybe_error的list中。

```
[  DEBUG 20200113 05:56:26 bert_detector:60] Loaded model ok, path: /raid/qinjie/workspace/pycorrect/pycorrector-master/pycorrector/bert/../data/bert_models/chinese_finetuned_lm, spend: 3.294 s.
[  DEBUG 20200113 05:56:27 bert_detector:103] prob:0.0015141394806781365, token:甚, idx:0
[  DEBUG 20200113 05:56:27 bert_detector:103] prob:0.7755396287298335, token:至, idx:1
[  DEBUG 20200113 05:56:27 bert_detector:103] prob:0.9644780914931264, token:出, idx:2
[  DEBUG 20200113 05:56:27 bert_detector:103] prob:0.9894069881667662, token:现, idx:3
[  DEBUG 20200113 05:56:27 bert_detector:103] prob:0.5164149121730598, token:交, idx:4
[  DEBUG 20200113 05:56:27 bert_detector:103] prob:0.8890835289160444, token:易, idx:5
[  DEBUG 20200113 05:56:27 bert_detector:103] prob:0.3664167345023212, token:几, idx:6
[  DEBUG 20200113 05:56:27 bert_detector:103] prob:0.44358985828916675, token:乎, idx:7
[  DEBUG 20200113 05:56:27 bert_detector:103] prob:0.0799107812120019, token:停, idx:8
[  DEBUG 20200113 05:56:27 bert_detector:103] prob:0.5120358801089798, token:之, idx:9
[  DEBUG 20200113 05:56:27 bert_detector:103] prob:0.9890874581924409, token:的, idx:10
[  DEBUG 20200113 05:56:27 bert_detector:103] prob:0.7367902998483208, token:情, idx:11
[  DEBUG 20200113 05:56:27 bert_detector:103] prob:0.995201951013315, token:况, idx:12
[  DEBUG 20200113 05:56:27 <ipython-input-3-410307b38cf9>:73] original text is: ['[CLS]', '[MASK]', '至', '出', '现', '交', '易', '几', '乎', '停', '之', '的', '情', '况', '[SEP]']
[  DEBUG 20200113 05:56:27 <ipython-input-3-410307b38cf9>:74] Mask predict is: 甚
[  DEBUG 20200113 05:56:27 <ipython-input-3-410307b38cf9>:73] original text is: ['[CLS]', '甚', '至', '出', '现', '交', '易', '几', '乎', '[MASK]', '之', '的', '情', '况', '[SEP]']
[  DEBUG 20200113 05:56:27 <ipython-input-3-410307b38cf9>:74] Mask predict is: 了
```

通过该样本以及大量样本发现，句子第一个字出现的概率往往很低，也就是说在没有任何上文出现的情况下，第一个字一定会被MASK, 根据第二个字来预测第一个字，通常能还原第一个字，所以就算第一个字概率低于阈值0.1，也可以通过预测一致而解决，但出现的问题是，以下为例：

```
[  DEBUG 20200113 05:56:31 bert_detector:103] prob:0.09367490685311335, token:标, idx:0
[  DEBUG 20200113 05:56:31 bert_detector:103] prob:0.020710760182397717, token:港, idx:1
[  DEBUG 20200113 05:56:31 bert_detector:103] prob:0.9953659745954992, token:房, idx:2
[  DEBUG 20200113 05:56:31 bert_detector:103] prob:0.9887592768144702, token:企, idx:3
[  DEBUG 20200113 05:56:31 bert_detector:103] prob:0.9126581549992174, token:必, idx:4
[  DEBUG 20200113 05:56:31 bert_detector:103] prob:0.9811513993017481, token:然, idx:5
[  DEBUG 20200113 05:56:31 bert_detector:103] prob:0.002190857629510787, token:条, idx:6
[  DEBUG 20200113 05:56:31 bert_detector:103] prob:0.7951315043321662, token:长, idx:7
[  DEBUG 20200113 05:56:31 bert_detector:103] prob:0.9898087061089897, token:市, idx:8
[  DEBUG 20200113 05:56:31 bert_detector:103] prob:0.9991462373210465, token:场, idx:9
[  DEBUG 20200113 05:56:31 bert_detector:103] prob:0.02792468514006478, token:的, idx:10
[  DEBUG 20200113 05:56:31 bert_detector:103] prob:0.8523879447266467, token:略, idx:11
[  DEBUG 20200113 05:56:31 <ipython-input-3-410307b38cf9>:73] original text is: ['[CLS]', '[MASK]', '港', '房', '企', '必', '然', '条', '长', '市', '场', '的', '略', '[SEP]']
[  DEBUG 20200113 05:56:31 <ipython-input-3-410307b38cf9>:74] Mask predict is: 香
[  DEBUG 20200113 05:56:31 <ipython-input-3-410307b38cf9>:73] original text is: ['[CLS]', '香', '[MASK]', '房', '企', '必', '然', '条', '长', '市', '场', '的', '略', '[SEP]']
[  DEBUG 20200113 05:56:31 <ipython-input-3-410307b38cf9>:74] Mask predict is: 港
[  DEBUG 20200113 05:56:31 <ipython-input-3-410307b38cf9>:73] original text is: ['[CLS]', '香', '港', '房', '企', '必', '然', '[MASK]', '长', '市', '场', '的', '略', '[SEP]']
[  DEBUG 20200113 05:56:31 <ipython-input-3-410307b38cf9>:74] Mask predict is: 成
[  DEBUG 20200113 05:56:32 <ipython-input-3-410307b38cf9>:73] original text is: ['[CLS]', '香', '港', '房', '企', '必', '然', '成', '长', '市', '场', '[MASK]', '略', '[SEP]']
[  DEBUG 20200113 05:56:32 <ipython-input-3-410307b38cf9>:74] Mask predict is: 策
```
corr sentence:标杆房企必然调整市场战略
 =>error sentence:标港房企必然条长市场的略
 => rectify sentence:('香港房企必然成长市场策略', [['标', '香', 0, 1], ['条', '成', 6, 7], ['的', '策', 10, 11]])

由于第一个字一定被mask，而第二个字是港字，所以预测为香港就不足为奇了，这反应了一个问题，就是第一个字一定被MASK的弊端，怎样调整代码解决这个问题是关键。

### bert mask检错机制
某字概率低于阈值会被MASK.

通过loss计算概率：
```python
    outputs = self.model(input_ids, masked_lm_labels=masked_lm_labels)
    masked_lm_loss, predictions = outputs[:2]
    prob = np.exp(-masked_lm_loss.item())
```
第一个字的概率如何计算？ 如上

后续字概率如何计算？ 在之前的被MASK数据得到预测结果后，使用预测结果的字进行概率计算，所以如果之前的字纠错失败，那么会产生连贯影响。
```python
    if corrected_item != item:
        sentence = before_sent + corrected_item + after_sent
        detail_word = [item, corrected_item, begin_idx, end_idx]
```

以前的检错做法是计算句子困惑度，若低于阈值，则用N-GRAM模型检错。Bert模型是计算单个字的概率，进行Mask检错，如果预测不是同一个字，那么认定检测到目标，否则pass.

## iqiyi的Faspell的检错方式和bert有何异同？
bert 得到[1,128,21128]的张量，即做映射词表将128维数据映射到词表上，得到结果