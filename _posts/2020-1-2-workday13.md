---
layout:     post
title:      workday13
subtitle:   
date:       2020-1-2
author:     RJ
header-img: 
catalog: true
tags:
    - job

---
<p id = "build"></p>
---

## Encoder_only 模型测试结果：
单层FFNN：

Test:
```
...

 the  7174 th example.
原文汉字id: 6491, 6481, 1082, 6104, 2930, 2010, 5291, 2391, 145, 3009, 5221
原文汉字： ['存', '在', '无', '法', '如', '期', '还', '贷', '的', '风', '险']
识别结果id: [6491, 6481, 1082, 6104, 2930, 2010, 5291, 2391, 145, 3009, 5221]
识别结果汉字：： 存在无法如期还贷的风险

 the  7175 th example.
原文汉字id: 4157, 4043, 2107, 2391, 3992, 145, 3162, 2162, 5746, 5972, 3004, 1119, 893
原文汉字： ['这', '令', '被', '贷', '款', '的', '员', '工', '们', '寝', '食', '难', '安']
识别结果id: [4157, 4043, 2107, 2391, 3992, 145, 3162, 2162, 5746, 5972, 6067, 6466, 893]
识别结果汉字：： 这令被贷款的员工们寝时南安


词错误率： 0.04870901541545363
```

多层FFNN:

Test:
```
...

 the  7174 th example.
原文汉字id: 3879, 1705, 3669, 5954, 6105, 1030, 12, 630, 475, 5328, 1919
原文汉字： ['存', '在', '无', '法', '如', '期', '还', '贷', '的', '风', '险']
识别结果id: [3879, 1705, 3669, 5954, 6105, 1030, 12, 630, 475, 5328, 1919]
识别结果汉字：： 存在无法如期还贷的风险

 the  7175 th example.
原文汉字id: 6561, 3902, 6505, 630, 2655, 475, 72, 2205, 4804, 6111, 6168, 6445, 4576
原文汉字： ['这', '令', '被', '贷', '款', '的', '员', '工', '们', '寝', '食', '难', '安']
识别结果id: [6561, 4997, 6505, 630, 2655, 475, 72, 2205, 4804, 6111, 5584, 4087, 4576]
识别结果汉字：： 这另被贷款的员工们寝石南安
词错误率： 0.03951701427003293
```

对比分析可知，多层FFNN的效果更好，目前使用：

train.tsv共计1,106,100条数据，大小为150M

ai_shell_test.txt数据共7176条数据，大小为1.2M

**最低错误率在3.951%，即正确率在96.049%左右。**


## 测试日常用语数据集1：
```
 the  11791 th example.
原文汉字id: 5065, 5771, 1705, 5697, 101, 830, 617
原文汉字： ['你', '住', '在', '江', '阴', '哪', '里']
识别结果id: [5065, 5771, 1705, 5697, 101, 830, 617]
识别结果汉字：： 你住在江阴哪里

 the  11792 th example.
原文汉字id: 2998, 2957, 962, 5060, 3896
原文汉字： ['不', '打', '三', '百', '了']
识别结果id: [2998, 2957, 962, 5060, 3896]
识别结果汉字：： 不打三百了

词错误率： 0.00843607491508312
```
**错误率在0.843%，即正确率在99.157%左右。** 看来日常短句拟合的效果已经很好了。

## 测试日常用语数据集2：
```
loading language model...
len==24279
INFO:tensorflow:Restoring parameters from ./logs_lm_improve/model_10
词错误率： 0.02764204253570328
```

将预测错误的数据汇总，进行分析：
![](https://raw.githubusercontent.com/rejae/rejae.github.io/master/img/202012errortxt.png)

对比发现，错误大部分集中于同音字，尤其是人名的错误率是较高的。

其次是拼音中的错误，由于直接拿过来的test数据，未经过数据格式校验，所以以后测试的时候，对测试数据也要进行校验。



## Encoder-Decoder代码调试

由于之前一个同学沿用项目源代码的数据加载方式，所以存在vocab两次创建的情况，其数据加载方式和我修改后的方式不同，所以要调试这个模型，首先要修改其数据加载方式。

除此之外，该模型的Test方法基本和原代码的Test方法一样，test的数据根本没有加载，测试还是使用的训练数据，而且只是测试10条，所以Test部分改动会比较大。

由于encoder-decoder结构在decoder过程中需要输入Label的embedding，所以汉字也需要进行lookup_table操作，所以pinyin和汉字要一同进入lookup_table。
```python
vocab += pny_vocab + han_vocab
```

调试train.py代码，得到错误：
```
ValueError: Variable decoder/num_blocks_0/multihead_attention/dense/kernel already exists, disallowed. Did you mean to set reuse=True or reuse=tf.AUTO_REUSE in VarScope? Originally defined at:

```

查阅相关问题:
[what-does-variable-reuse-mean-in-tensorflow](https://medium.com/@hideyuki/what-does-variable-reuse-mean-in-tensorflow-40e86535026b)
```
I don't get this error with neither of the two TensorFlow versions. Note that code block 3 should only be executed once! 

If you want to execute the block of the graph creation again, TensorFlow will raise this error, because the graph (with it's layer names) already exists. 

If you run this notebook block after block there should be absolutely no problem.

In the case you want to re-run codeblock 3 (for what ever reason) just insert a simple tf.reset_default_graph() at the beginning of the block. 

This will reset the graph you have already create and though you can create it again.
```
设置，reuse=tf.AUTO_REUSE 

## 下一步任务

跟同学讨论了一下，他负责的语音模型的错误率大概在15%~20%左右。如果语音到拼音这块错误率较高了，那么下游的语言模型精度也会受到严重的影响。所以商量之后，意识到核心应该放在纠错这块。

讨论，声学模型得到拼音，假定有20%的错误率，能否在拼音这块就开始纠错？

考虑到
- 一个拼音对应多个汉字
- 拼音不能像中文做分词
- 一个拼音识别错，将直接导致汉字预测出错


考虑到错误：
```
fu4 jin4 zhong1 guo2 yi1 dong4 tong1 qi4 you3 xiang4 gong1 si1
附近中国移动通信有限公司
附近中国一动通气有象公司
```

假定我们先对拼音进行纠错，如：yi1 dong4 tong1 qi4

在语言模型中，普遍用大量自监督语料，进行训练，得到语言模型。那么我们能否用大量的拼音，做拼音的语言模型？

如果采用了这一思想，那么不同的拼音之间将发生关联，如同汉字的词语之间的关联。放到自回归语言模型里面，一句话的pinyin 序列，将得到一个语言模型得分。当某句话的得分低于阈值，那么可以判定该pinyin序列可能有误。

那如何定位到错误位置？


对预测得到的中文句子进行纠错：

容易发现，在80%以上的语音识别正确率的情况下，即使拼音发生了错误，但是整句话的意思还是很明确。

可以对预测到的句子，进行分词，附近 / 中国/ 一动通气 / 有象 / 公司

使用分词，进行常用词对比，从词粒度检错。

使用语言模型困惑度，进行字粒度的检错。


## 参考分析pycorrector工具
[pycorrector](https://github.com/shibing624/pycorrector)

[中文纠错技术简述](https://zhuanlan.zhihu.com/p/82807092)

### 背景与意义

在通用领域中，中文文本纠错问题是从互联网起始时就一直在寻求解决的问题。在搜索引擎中，一个好的纠错系统能够用户输入的查询词进行纠错提示，或直接展示正确答案。

当前由于用户输入随意及手写输入法易出错等原因，错误串在输入文本中占比高达10%-15%，这也使得中文文本纠错模块必要性凸显。而在垂直领域中，比如平安的寿险领域，同样会因为用户输入随意、不清楚产品名称等原因，导致用户提问与回答存在大量的手写及同音错误。

自然语言处理常见的任务包括词法分析、句法分析、用户意图识别等，而要取得理想的结果，输入数据的准确性是基本前提。一旦语言使用者对语言掌握不够或粗心大意，从而造成用词不当、张冠李戴等错误时，很容易引起“差之毫厘，谬以千里”的“蝴蝶效应”。因此，文本纠错对NLP技术整体的性能保证起着至关重要的作用。

### 业界主流方案

业界纠错主流方案一般包括错误检测→候选召回→候选排序三部分，根据作者调研工作其技术方案主要可分为以下三种：

① 基于规则式的通用纠错库pycorrector；
② 基于大样本训练深度学习模型的检错算法，以百度纠错系统为代表；
③ 基于垂直领域的DCQC纠错框架。

### 学术界的进展

学术界近期发表的中文纠错论文主要集中在中文纠错比赛项目上，如：SIGHAN举办的CSC（中文拼写纠错）比赛、IJCNLP举办的CGED（中文语法错误诊断）比赛及NLPCC举办的GGED（中文语法错误诊断）比赛等。

2.3.1 LSTM+CRF序列标注用于错误检测

IJCNLP2017 [3]和2018 [4]的CGED比赛任务中，第一名的方法都用了LSTM+CRF用于错误位置的检测。然而文中，该方法在错误位置检测方面的F1值最高也只有0.39，目前还没有达到工业化使用的要求。

2.3.2 NMT基于神经机器翻译模型纠错方法

基于机器翻译模型的纠错方法的思想是，将纠错任务类比于机器翻译任务，预想利用模型将错误语句翻译为正确语句，利用Seq2seq模型完成端到端的纠正过程。

YUAN等学者在2016首次利用双向RNN编码器+单向RNN解码器+Attention的经典结构对CoNll-2014(英文语料)进行语法纠错，达到当时最好效果，其统计指标F0.5为39.9%；其后，有道团队在NLPCC-2018举办的CGEC比赛中利用Transformer的翻译模型达到比赛最好的结果，其F0.5值 为29.9% [5]。