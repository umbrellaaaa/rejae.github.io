---
layout:     post
title:      work day1
subtitle:   
date:       2019-12-17
author:     RJ
header-img: 
catalog: true
tags:
    - NLP
---
<p id = "build"></p>
---

## 环境搭建

1. putty

2. winscp

3. 环境配置




conda install ipykernel
source activate 环境名称
python -m ipykernel install --user --name 环境名称 --display-name "Python (环境名称)"



start_jupyter.sh

nohup jupyter notebook --ip=192.168.100.76 --allow-root &


http://192.168.100.xxx:8889/?token=xxx





## 参考

[服务器外部jupyter访问](https://blog.csdn.net/mmc2015/article/details/52439212)

## 问题与解决
由于本地下载速度较慢，配置环境后才能在本地进行debug。所以在调试test.py文件的时候遇到:

FileNotFoundError: [Errno 2] No such file or directory: 'data/data_thchs30/train/A11_0.wav'

第一时间不能调试代码发现错误，回溯代码发现缺少thchs30文件，遂查找到文件：

http://www.openslr.org/18/

原始文件大小6G有多，在下载过程中，阅读数据说明。

## 讨论和学习
和前一个实习生交流了一下，明确了自己接下来需要做的事情：

1. 数据清洗
2. Transformer 掌握其原理，熟练应用此模型。
3. Transformer 添加拼音到汉字的纠错功能。




[transformer.ipynb](https://github.com/tensorflow/docs/blob/master/site/zh-cn/tutorials/text/transformer.ipynb)

[Texar](https://github.com/asyml/texar/tree/master/texar/tf/modules)

[tensor2tensor](https://github.com/tensorflow/tensor2tensor/tree/master/tensor2tensor/models)

[https://pypi.org](https://pypi.org)

[official transformer](https://github.com/tensorflow/models)

http://192.168.100.76:8809/notebooks/workspace/DeepSpeechRecognition-master/test.ipynb


## 项目中的Transformer代码调试

```python
##emb得到句子x通过lookuptabel映射得到三维[batch, seq_len  100, embedding_size  512]
self.emb = embedding(self.x, vocab_size=self.input_vocab_size, num_units=self.hidden_units, scale=True, scope="enc_embed")

##tf.tile(tf.expand_dims(tf.range(tf.shape(self.x)[1]), 0),[tf.shape(self.x)[0], 1]) 
##完成输入input shape=[vocab_size,embedding_size]的positional embedding的维度配对，并且shape[1]中的数据是0,1,...shape[1]-1的位置编码

position_emb = embedding(tf.tile(tf.expand_dims(tf.range(tf.shape(self.x)[1]), 0),[tf.shape(self.x)[0], 1]),                                                                   vocab_size=self.max_length,
                                            num_units=self.hidden_units,
                                            zero_pad=False,
                                            scale=False,
                                            scope="enc_pe")

self.enc = self.emb + position_emb

## Dropout
self.enc = tf.layers.dropout(self.enc, 
                            rate=self.dropout_rate, 
                            training=tf.convert_to_tensor(self.is_training))


```

## 代码问题
1. 为什么不用原文的sin,cos位置编码，而使用一般的整数序列编码？
2. 思考embedding+position_emb之后就使用dropout的意义在哪里？
3. key mask和 query mask的意义？


## tensorflow model: Transformer学习

1. 位置编码
```python
def get_position_encoding(
    length, hidden_size, min_timescale=1.0, max_timescale=1.0e4):
  """Return positional encoding.

  Calculates the position encoding as a mix of sine and cosine functions with
  geometrically increasing wavelengths.
  Defined and formulized in Attention is All You Need, section 3.5.

  Args:
    length: Sequence length.
    hidden_size: Size of the
    min_timescale: Minimum scale that will be applied at each position
    max_timescale: Maximum scale that will be applied at each position

  Returns:
    Tensor with shape [length, hidden_size]
  """
  # We compute the positional encoding in float32 even if the model uses
  # float16, as many of the ops used, like log and exp, are numerically unstable
  # in float16.
  position = tf.cast(tf.range(length), tf.float32)
  num_timescales = hidden_size // 2
  log_timescale_increment = (
      math.log(float(max_timescale) / float(min_timescale)) /
      (tf.cast(num_timescales, tf.float32) - 1))
  inv_timescales = min_timescale * tf.exp(
      tf.cast(tf.range(num_timescales), tf.float32) * -log_timescale_increment)
  scaled_time = tf.expand_dims(position, 1) * tf.expand_dims(inv_timescales, 0)
  signal = tf.concat([tf.sin(scaled_time), tf.cos(scaled_time)], axis=1)
  return signal
```


