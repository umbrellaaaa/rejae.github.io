---
layout:     post
title:      生成对抗网络
subtitle:   cheer up
date:       2019-10-22
author:     RJ
header-img: 
catalog: true
tags:
    - GAN
---
## 前言
深度学习的有本书上最后一章就是GAN，以前翻看觉得讲的很简单，没有涉及原理，然后又有很多扩展如：DCGAN, InfoGAN, AC-GAN, AEGAN, WGAN, WGAN-GP, LSGAN, SRGAN。就没有欲望去看了。<br>
现在看论文**Generative Adversarial Nets**，再结合网上的代码认真学习一下这个组合网络。

<p id = "build"></p>
---

## 正文
生成对抗网络由 Ian Goodfellow 于 2014 年提出。GAN 不是神经网络应用在无监督学习中的唯一途径，还有玻尔兹曼机（Geoffrey Hinton 和 Terry Sejnowski，1985）和自动解码器（Dana H. Ballard，1987）。三者皆致力于通过学习恒等函数 f（x）= x 从数据中提取特征，且都依赖马尔可夫链来训练或生成样本。

GAN 设计之初衷就是避免使用马尔可夫链，因为后者的计算成本很高。相对于玻尔兹曼机（只有几个概率分布适用于马尔可夫链抽样）的另一个优点是 GAN 的限制要少得多。

To learn the Generator’s distribution, p_g over data x, the distribution on input noise variables p_z(z) should be defined. Then G(z, θ_g) maps z from latent space Z to data space and D(x, θ_d) outputs a single scalar — probability that x came from the real data rather than p_g.
为了使生成器学习到真实数据x的分布参数p_g, 首先需要定义输入噪声变量z的分布p_z(z)。随后生成器G(z, θ_g)将z从潜在空间映射到数据空间。判别器输出一个概率标量，这个概率标量为输入样本是真实数据的概率

The Discriminator is trained to maximize the probability of assigning the correct label to both examples of real data and generated samples. While the Generator is trained to minimize log(1 — D(G(z))). In other words — to minimize the probability of the Discriminator’s correct answer.

## 参考代码
```python

from keras.datasets import mnist
from keras.layers import Dense, Dropout, Input
from keras.models import Model,Sequential
from keras.layers.advanced_activations import LeakyReLU
from keras.optimizers import Adam

from tqdm import tqdm
import numpy as np
import matplotlib.pyplot as plt
%matplotlib inline

path = './Result_GAN/'

# Load the dataset
def load_data():
    (x_train, y_train), (_, _) = mnist.load_data()
    x_train = (x_train.astype(np.float32) - 127.5)/127.5
    x_train = x_train.reshape(60000, 784)
    return (x_train, y_train)

X_train, y_train = load_data()
print(X_train.shape, y_train.shape)
## 生成器构建
def build_generator():
    model = Sequential()
    
    model.add(Dense(units=256, input_dim=100))
    model.add(LeakyReLU(alpha=0.2))
    
    model.add(Dense(units=512))
    model.add(LeakyReLU(alpha=0.2))
    
    model.add(Dense(units=1024))
    model.add(LeakyReLU(alpha=0.2))
    
    model.add(Dense(units=784, activation='tanh'))
    
    model.compile(loss='binary_crossentropy', optimizer=Adam(0.0002, 0.5))
    return model

generator = build_generator()
generator.summary()

## 判别器构建

def build_discriminator():
    model = Sequential()
    
    model.add(Dense(units=1024 ,input_dim=784))
    model.add(LeakyReLU(alpha=0.2))
    model.add(Dropout(0.3))
       
    model.add(Dense(units=512))
    model.add(LeakyReLU(alpha=0.2))
    model.add(Dropout(0.3))
       
    model.add(Dense(units=256))
    model.add(LeakyReLU(alpha=0.2))
    model.add(Dropout(0.3))
      
    model.add(Dense(units=1, activation='sigmoid'))
    
    model.compile(loss='binary_crossentropy', optimizer=Adam(0.0002, 0.5))
    return model
  
discriminator = build_discriminator()
discriminator.summary()

## 合并网络
def build_GAN(discriminator, generator):
    discriminator.trainable=False
    GAN_input = Input(shape=(100,))
    x = generator(GAN_input)
    GAN_output= discriminator(x)
    GAN = Model(inputs=GAN_input, outputs=GAN_output)
    GAN.compile(loss='binary_crossentropy', optimizer=Adam(0.0002, 0.5))
    return GAN
  
GAN = build_GAN(discriminator, generator)
GAN.summary()

def draw_images(generator, epoch, examples=25, dim=(5,5), figsize=(10,10)):
    noise= np.random.normal(loc=0, scale=1, size=[examples, 100])
    generated_images = generator.predict(noise)
    generated_images = generated_images.reshape(25,28,28)
    plt.figure(figsize=figsize)
    for i in range(generated_images.shape[0]):
        plt.subplot(dim[0], dim[1], i+1)
        plt.imshow(generated_images[i], interpolation='nearest', cmap='Greys')
        plt.axis('off')
    plt.tight_layout()
    plt.savefig(path+'Generated_images %d.png' %epoch)


## 训练网络
def train_GAN(epochs=1, batch_size=128):
    
  #Loading the data
  X_train, y_train = load_data()

  # Creating GAN
  generator= build_generator()
  discriminator= build_discriminator()
  GAN = build_GAN(discriminator, generator)

  for i in range(1, epochs+1):
    print("Epoch %d" %i)
    
    for _ in tqdm(range(batch_size)):
      # Generate fake images from random noiset
      noise= np.random.normal(0,1, (batch_size, 100))
      fake_images = generator.predict(noise)

      # Select a random batch of real images from MNIST
      real_images = X_train[np.random.randint(0, X_train.shape[0], batch_size)]

      # Labels for fake and real images           
      label_fake = np.zeros(batch_size)
      label_real = np.ones(batch_size) 

      # Concatenate fake and real images 
      X = np.concatenate([fake_images, real_images])
      y = np.concatenate([label_fake, label_real])

      # Train the discriminator
      discriminator.trainable=True
      discriminator.train_on_batch(X, y)

      # Train the generator/chained GAN model (with frozen weights in discriminator) 
      discriminator.trainable=False
      GAN.train_on_batch(noise, label_real)

    # Draw generated images every 15 epoches     
    if i == 1 or i % 10 == 0:
      draw_images(generator, i)

train_GAN(epochs=50, batch_size=128)
```
## 后记
参考内容：<br>
[让我们跑一个最简单的GAN网络吧！](https://zhuanlan.zhihu.com/p/85908702)<br>
[谷歌introduction.](https://developers.google.com/machine-learning/gan)<br>
[Generative Adversarial Net.](https://papers.nips.cc/paper/5423-generative-adversarial-nets.pdf)
