---
layout:     post
title:      workday4
subtitle:   
date:       2019-12-20
author:     RJ
header-img: 
catalog: true
tags:
    - Learning
---
<p id = "build"></p>
---

## 本机调试代码：

使用thchs和aishel数据训练Transformer代码。
```
    134     def han2id(self, line, vocab):
--> 135         return [vocab.index(han) for han in line]
    136 
    137     def wav_padding(self, wav_data_lst):

ValueError: ' ' is not in list

修改代码

    def mk_am_vocab(self, data):
        vocab = []
        for line in tqdm(data):
            line = line
            for pny in line:
                if pny not in vocab:
                    vocab.append(pny)
        vocab.append('_')
 -----> vocab.append(' ')
        return vocab
```

## 服务器相关问题：

![](https://raw.githubusercontent.com/rejae/rejae.github.io/master/img/XLA_GPU20191220144918.png)

切换到已有环境测试：

![](https://raw.githubusercontent.com/rejae/rejae.github.io/master/img/GPU20191220145055.png)

问题所在： XLA_GPU 不兼容低版本tensorflow，无法使用服务器资源。

切换到已有环境后，可以执行训练。

由于tensorflow版本降低后，出现问题：
```
AttributeError: module 'tensorflow.python.ops.nn' has no attribute 'softmax_cross_entropy_with_logits_v2'
```
查阅资料：
```
这个api是废弃api tf.nn.softmax_cross_entropy_with_logits的新版

被废弃的旧版：反向传播时，只会反向传播logits，label不会反向传播（具体怎么理解还未可知）

v2新版：反向传播时，logits和labels都会反向传播

You have every reason to be confused, because in supervised learning one doesn't need to backpropagate to labels. They are considered fixed ground truth and only the weights need to be adjusted to match them.

But in some cases, the labels themselves may come from a differentiable source, another network. One example might be adversarial learning. In this case, both networks might benefit from the error signal. That's the reason why tf.nn.softmax_cross_entropy_with_logits_v2 was introduced. Note that when the labels are the placeholders (which is also typical), there is no difference if the gradient through flows or not, because there are no variables to apply gradient to.
```

因为我们采用supervised leraning，所以直接切换到低版本的情况下无影响。

仅使用thchs数据训练，分析数据集：

train:10000  dev:893  test:2498

使用原始参数进行训练，得到avg_loss:
```

```
耗时：
```

```

为代码添加超参数写入方法，以保存超参数，方便后续对比调优实验。

分析模型权重参数，如果可以可视化注意力最好。


## 总结
- 周一刚入职，下午4点拿到工作电脑后就开始着手相关任务。
- 周二搭建环境，熟悉项目代码。
- 周三详细分析transformer代码，分析张量变换，分析各个模块的作用。
- 周四调试程序，遇到服务器XLA_GPU问题，尝试修改keras源代码以使用XLA_GPU，最终失败。
- 周五厘清相关问题，找同事解决，切换到已有环境中，问题得到解决，但是此环境中的GPU大家都在用，无法训练调试模型。

