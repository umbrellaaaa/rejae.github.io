---
layout:     post
title:      文本分类进阶
subtitle:   
date:       2020-4-29
author:     RJ
header-img: 
catalog: true
tags:
    - nlp

---
<p id = "build"></p>
---

## 文本分类

- 传统机器学习 tf-idf  cv特征+ ML
- 深度学习: CNN LSTM BERT + softmax
- 更细细粒度

## 基于aspect的情感分析：ABSA

[Aspect-Based Sentiment Analysis, ABSA](https://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&mid=2247505078&idx=1&sn=15440251e2a4e7ca343a167abc4baaa7&chksm=96ea0b36a19d82205149d0bbf2abe021446ec6f79080240a5bb86e8f7ca269d79fb8497a2c7b&scene=0&xtrack=1&key=c4387a049ca2dc9df16499072459d681387c6ed2cf558b2b752ac108228b54429e6cc2821aa364173ef43324832b64f9d21f8085c3f5f1e020af685b1fec5501dbb001acb0bf947ffa5b746d7a86c82f&ascene=1&uin=MTkxMDM0MzYyNg%3D%3D&devicetype=Windows+7&version=62080079&lang=zh_CN&exportkey=A2%2Bqkjz1NvqtsE1NOunwAXM%3D&pass_ticket=oFyGvW7pHugVmpRBd44FyTBDfZuoCNRBDs%2F4vaJzsaU0%2Bl63PU47S4D4cQlhiWW%2F)


举个例子，用户在某条餐厅评论中 “waiters are unfriendly but the pasta is out of this world.”，对 “waiters” 和 “pasta” 两个方面分别表达了负面的情感和正面的情感。

普通的文档 / 句子级情感分析并不能完成这种细粒度的分析任务，ABSA 也因此成为近些年情感分析的热点研究问题。

典型的 ABSA 能够帮助分析评论文本中具体方面的情感极性（正面、负面、中性），但无法提供用户在每个方面的具体观点，如上例中 “waiters” 是 “unfriendly” 的，“pasta” 是 “out of this world” 的。

显然，这些观点词解释了用户对某些方面产生相应情感的原因。为此，我们提出了一个新的细粒度情感分析子任务——面向目标的观点词抽取（Target-oriented Opinion Words Extraction，TOWE），旨在从评论文本中抽取出给定目标（target）对应的观点词（opinion words）。

在 TOWE 任务中，目标对象（target）是提前给定的，和 aspect 表达了相同的含义，都是指评论文本中商品/服务的具体方面 / 属性。以上面的句子为例，当给定目标是“waiters”时，TOWE 需要抽取 “unfriendly” 作为 “waiters” 的观点词；当给定目标为 “pasta”，TOWE 则会抽取观点词 “out of this world”。


- NAACL19 “Target-oriented Opinion Words Extraction with Target-fused Neural Sequence Labeling” [4] 这篇工作定义了 TOWE 任务，并且给出一个鲁棒的融合目标信息的神经序列化标注模型。
```
论文标题：Target-oriented Opinion Words Extraction with Target-fused Neural Sequence Labeling
论文来源：NAACL 2019
论文链接：https://www.aclweb.org/anthology/N19-1259
代码链接：https://github.com/NJUNLP/TOWE
```
- 考虑到标注大量细粒度情感分析数据是耗时且困难的，AAAI20 中的工作 “Latent Opinions Transfer Network for Target-Oriented Opinion Words Extraction” [5] 从迁移学习的角度出发，提出潜在观点迁移网络，从资源丰富的评论情感分类数据中迁移潜在观点知识来辅助提升 TOWE.
```
论文标题：Latent Opinions Transfer Network for Target-Oriented Opinion Words Extraction
论文来源：AAAI 2020
论文链接：https://arxiv.org/abs/2001.01989
代码链接：https://github.com/NJUNLP/TOWE
```


## 融合目标信息的神经序列化标注模型

不同于普通的序列化标注任务，TOWE 的难点在于对同一个句子，如果输入的目标对象不同，那么对应标注的观点词也应该不同。

容易想到，问题核心在于如何建模 target 和上下文之间的语义关系，从而得到 target-specific 的文本表示。受模型 TD-LSTM [6] 的启发，我们以 LSTM 作为基础组件，设计了一个融合目标信息的神经序列化标注模型 IOG。

IOG 采用 encoder-decoder 框架，encoder 中包含了三个组件，分别是 Inward-LSTM，Outward-LSTM 和Global LSTM。我们根据目标对象的位置将评论句子分为三个部分：上文、target、下文。