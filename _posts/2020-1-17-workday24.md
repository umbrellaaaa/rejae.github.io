---
layout:     post
title:      workday24
subtitle:   
date:       2020-1-17
author:     RJ
header-img: 
catalog: true
tags:
    - job

---
<p id = "build"></p>
---

## 昨天的issue得到作者回复：
```
Q:你好，代码中有多轮调试么？轮次设为多少也是一个问题？

R:论文最后一节中有给出纠错轮数和性能的关系的实验结果；代码中由faspell_configs中的round控制；
```

![](https://raw.githubusercontent.com/rejae/rejae.github.io/master/img/20200117092725.png)

- The four plots in the first row show how the number of candidates for each character affects F1
performances.
- The four in the second row show the impact of the number of rounds of spell checking.

但是这里只是针对那三个数据集得到的结果，真实场景下，一个句子错字多少是不定的，这个根本解决不了问题.

于是追问作者：

您好，这里的纠错轮数和效果曲线是根据那三个相关数据集得到的，据我调试代码，发现一句话每次纠错有且只有一个字（即使原句是正确的，也会因为候选按confidence排序，截断confidence最高的origin，阻止其进入error_delete_positions，所以即使该字正确也会被候选confidence排第二的替换），当轮次多了之后，替换会更严重，所以我以为这里的效果曲线只是针对那三个数据集的。

真实纠错场景下，一个句子错误多少是未确定的，单纯按您实验的轮次与效果是不具备参考意义的，请问这个问题（每次纠错有且只有1个，即使正确也纠错，多次纠错次数也不确定），有解决么？

-----

## 关掉n_gram_bias
```
INFO:root:spell checking sentence 本是几经济报道
INFO:root:spell checking on rank=0
INFO:root:本 --> <PASS-21> (con=0.5052680969238281, sim=0.0, on_top_difference=True)
INFO:root:spell checking on rank=1
INFO:root:本 --> <PASS-华> (con=0.16983197629451752, sim=0.0, on_top_difference=True)
INFO:root:spell checking on rank=2
INFO:root:本 --> <PASS-世> (con=0.056517526507377625, sim=0.0, on_top_difference=True)
INFO:root:spell checking on rank=3
INFO:root:本 --> <PASS-据> (con=0.027903379872441292, sim=0.0, on_top_difference=True)
INFO:root:spell checking on rank=4
INFO:root:本 --> <PASS-京> (con=0.02510400302708149, sim=0.23666666666666664, on_top_difference=True)
INFO:root:spell checking on rank=0
INFO:root:是--> 世 (con=0.9937990307807922, sim=0.6333333333333334, on_top_difference=True)
INFO:root:spell checking on rank=0
INFO:root:几--> 纪 (con=0.9049928784370422, sim=0.8333333333333334, on_top_difference=True)
INFO:root:spell checking on rank=0
INFO:root:经 --> <PASS-经> (con=0.9928998947143555, sim=null, on_top_difference=False)
INFO:root:spell checking on rank=1
INFO:root:经--> 世 (con=0.0017895877826958895, sim=0.0, on_top_difference=False)
INFO:root:spell checking on rank=0
INFO:root:济 --> <PASS-济> (con=0.9835466146469116, sim=null, on_top_difference=False)
INFO:root:spell checking on rank=1
INFO:root:济--> 经 (con=0.002822480397298932, sim=0.2, on_top_difference=False)
INFO:root:spell checking on rank=0
INFO:root:报 --> <PASS-报> (con=0.4182172417640686, sim=null, on_top_difference=False)
INFO:root:spell checking on rank=1
INFO:root:报--> 新 (con=0.1428574174642563, sim=0.0, on_top_difference=False)
INFO:root:spell checking on rank=0
INFO:root:道 --> <PASS-道> (con=0.7591613531112671, sim=null, on_top_difference=False)
INFO:root:spell checking on rank=1
INFO:root:道--> 闻 (con=0.09496999531984329, sim=0.0, on_top_difference=False)
本世纪世经新闻
INFO:root:current sentence is corrected to 本世纪世经新闻
```
几字成功被替换，但是又引入了其他字。

##　调节curve曲线

调节curve曲线，根据confidence和similarity过滤低概率的字，error应该被置为None。

但是反复调试，却不能置为None。

最终查找到原因：317 row

```
    error = self.get_error(sentences[i],
                            j - 1,
                            cand_tokens,
                            rank=rank,
                            difference=cand_tokens[0][0] != sentences[i][j - 1],
                            filter_is_on=filter_is_on, sim_type=sim_type)
```
关键代码：
```
difference=cand_tokens[0][0] != sentences[i][j - 1]
```

该段代码，将候选中的top1与原字比较，若不同，则difference为True，在调用曲线的时候，调用1:对应的曲线。

但是若top1与原字相同，那么，difference为False，在调用曲线的时候，调用0:对应的曲线。而0曲线没有做修改，默认返回True。

思考，作者为什么在这里设置这样的机制？

这里显然关注候选top1与原字的关系，若不相等，则调用1曲线，这里应该是检错，然后进1曲线

若相等，调用0曲线，这里预测与原字相同的情况下，0曲线应该过滤相当大，因为尝试告诉我们，预测和原字相同的情况下，该字应该是正确的。

所以我将曲线1的过滤，加到曲线0中即可。
```
INFO:root:spell checking on rank=0
INFO:root:济 --> <PASS-济> (con=0.9835466146469116, sim=null, on_top_difference=False)
INFO:root:spell checking on rank=1
INFO:root:济 --> <PASS-经> (con=0.002822480397298932, sim=0.2, on_top_difference=False)
INFO:root:spell checking on rank=2
INFO:root:济--> 界 (con=0.0018490676302462816, sim=0.675, on_top_difference=False)

INFO:root:current sentence is corrected to 本世纪经界报道
```
对比之前结果：本世纪世经新闻

效果已经好了很多，但是这里，济字被替换为界字了，原因在哪里？

查看：ji4 和jie4的编辑距离较经的编辑距离小为0.675，而且:

flag = 2 * confidence + 3 * similarity - 2 > 0 

为True，所以进入了error。

所以这个曲线的设定有讲究，调低一下similarity.

作者提供的similarity和confidence的默认参数为：
```python
        flag1 = 20 / 3 * confidence + similarity - 21.2 / 3 > 0
        flag2 = 0.1 * confidence + similarity - 0.6 > 0
```

一般预测top1与origin相同的情况下（rank==0），直接返回error = None

rank>0后面的结果，若过滤曲线未将其过滤掉，则error会append该item.

如上面说的“若相等，调用0曲线，这里预测与原字相同的情况下，0曲线应该过滤相当大，因为尝试告诉我们，预测和原字相同的情况下，该字应该是正确的。所以我将曲线1的过滤，加到曲线0中即可。”

事实证明，曲线0的过滤力度应该更大，因为济被替换为界字了，因为编辑距离很小，相似度很高。
```
    @staticmethod
    def curve_00(confidence, similarity):
        count = 5*confidence + 2*similarity - 2
        flag = 5*confidence + 2*similarity - 2 > 0
        if flag:
            print(count )
            return True
        return False

```

经过调整后：

```
本世纪经济报道
INFO:root:current sentence is corrected to 本世纪经济报道
INFO:root: 0 errors are deleted to prevent n-gram bias problem
INFO:root:**************************************************

Elapsed time: 0.0 min 0.7743542194366455 s in generating candidates for 1 sentences;
              0.006339073181152344 s in filtering candidates for 1 sentences;
Speed: 774.3542194366455 ms/sentence in generating and 6.339073181152344 ms/sentence in filtering 

Process finished with exit code 0

```
得到正确结果：本世纪经济报道



## 分析
所以iqiyi代码在纠错上只是针对了那三个数据集调优，没参考过以前的项目，不知道他们是怎么做的，反正iqiyi的代码问题很大，每次纠错有且仅有一个字，无论对错，轮次也不定。所以那三个数据集效果比以前人好，也只是调试特定的轮次+基准效果提升而已，核心问题：检错多少个字。  并没有得到解决。

所以可以为项目添加检错机制，为句子的轮次提供依据。简单的，检错可以根据Bert MASK概率来计算，但是这里又回到之前我调试Bert的问题，第一个字的confidence概率很低。

这里先对第一个字不处理，即默认第一个字是正确的(为了快速得到一个较好的结果，当然后面调优的时候这里可以采用N-gram，将第一个字与后面的字组成词或短语，计算confidence。)

## 基准调优方案
所以大概思路是：

- 使用爱奇艺的模块，得到一句话中每个字的candidates
- 对首个字的candidate暂时不作处理，即默认其正确，不做替换
- 对其他字，按bert MASK该位置后，得到该字的candidates对应的confidence。对于confidence从高到低排序后：
    - 若最高位非原字，并且根据similarity和confidence的组合计算 与 原低confidence的origin计算 做差，若大于某个阈值，则进行替换。
    - 若最高位是原字，则不进行替换，保留原字。

这里做的提升在于：

1. 根据confidence排序，首先判断该字是否存在问题
2. 根据confidence和similarity共同判断，该可能存在问题的位置，是否要进行替换。


xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
缺点在于：

对于首字，我们不进行处理，因为不稳定，这是由于只有下文，bert MASK第一个位置之后，在只提供下文的情况下，该位置的选择太多太多。（后续可以考虑N-gram计算组合概率）

最终，这里检错部分：我们使用bert MASK的confidence计算。而纠错部分也是根据Bert产出的候选召回，所以这个模型和Bert纠错最大的区别在哪里呢？

第一，在于预训练的时候将拼音similarity加入到模型中。

第二，在纠错的时候将拼音的similarity一同进行计算。

xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx

调节模型，根据filter曲线可以解决这个问题，即候选被filter淘汰掉，首字概率低也保留。

## 难点：组合作差计算
这里对每个字根据similarity和confidence的组合计算 与 原低confidence的origin计算 做差，需要进行实验。






## 阅读 Chinese Spelling Check Evaluation at SIGHAN Bake-off 2013
[Chinese Spelling Check Evaluation at SIGHAN Bake-off 2013](https://www.aclweb.org/anthology/W13-4406.pdf)

