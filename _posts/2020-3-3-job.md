---
layout:     post
title:      job
subtitle:   
date:       2020-3-3
author:     RJ
header-img: 
catalog: true
tags:
    - job

---
<p id = "build"></p>
---

## kenlm

下载安装并调试kenlm模型，使用2014人民日报语料训练N-gram语言模型。

需要安装很多dependency文件，包括：
```python
1、boost
在boost官网下载boost：http://www.boost.org，这里下载了boost 1.67

cd boost
./bootstrap.sh
./b2 install

2、xz
wget http://tukaani.org/xz/xz-5.2.2.tar.gz
tar xzvf xz-5.2.2.tar.gz
cd xz-5.2.2
./configure
make
make install

3、zlib
wget http://zlib.net/zlib-1.2.11.tar.gz
tar xzf zlib-1.2.11.tar.gz
cd zlib-1.2.11
./configure
make
make install

4、bzip
wget https://fossies.org/linux/misc/bzip2-1.0.6.tar.gz
tar xzvf bzip2-1.0.6.tar.gz
cd bzip2-1.0.6/
make
make install

5、libbz2-dev
apt-get install libbz2-dev

5、kenlm
在官网下载 http://kheafield.com/code/kenlm.tar.gz，解压

cd kenlm
mkdir build
cd build
cmake ..
make
python setup.py install
```

使用2014人民日报语料，训练模型：

```
wget -O - https://kheafield.com/code/kenlm.tar.gz |tar xz
mkdir kenlm/build
cd kenlm/build
cmake ..
make -j2

build/bin/lmplz -o 3 --verbose_header --text 2014corpus.txt --arpa 2014corpus.arps
```


安装完成后，在python环境中，pip install https://github.com/kpu/kenlm/archive/master.zip

模型的使用：

需要注意的是：我们用的人民日报语料是分词且带词性的，所以我们在使用模型的时候需要对应的输入：

使用jieba，将句子切分成对应的形式：
```python
import jieba.posseg as pseg
words = pseg.cut("三司限城市")
sentence = ''
for word, flag in words:
    sentence=sentence+word+'/'+flag+' '
print(sentence)

out:三司/n 限/v 城市/ns 
```

对句子切分后，得到各个组合的分数结果：
```python
import kenlm
model = kenlm.LanguageModel('/data/language/chenyi/kenlm/kenlm/build/lm.bin')

print(model.score('三司/n 限/v 城市/ns', bos=False, eos=False))
print(model.score('三/m 司线/n 城市/ns', bos=False, eos=False))
print(model.score('三四/m 限/v 城市/ns', bos=False, eos=False))
print(model.score('三四/m 线/n 城市/ns', bos=False, eos=False))
out:

-17.74773406982422
-16.960710525512695
-17.302309036254883
-16.745254516601562
```
可以看到，三四线城市的score是较大的，所以纠错正确。

## 处理bert result.json文件
```python
import json
with open("results_0.json", 'r') as f:
    temp = json.loads(f.read())
    
    for item in temp[3:]:
        print(item)
        print('\n')
        original_sentence = item['original_sentence']
        corrected_sentence = item['corrected_sentence']        
        num_errors = item['num_errors']        
        errors = item['errors']
        for item in errors:
            print(item)
            
        break
```
```python
{'original_sentence': '因此土地储备之观重要', 'corrected_sentence': '因此土地儲备非观重要', 'num_errors': 2, 'errors': [{'error_position': 4, 'original': '储', 'corrected_to': '儲', 'candidates': {'储': 0.9982870221138, '儲': 0.0001897053443826735, '贮': 0.00012521656753960997, '库': 0.00011806152906501666, '保': 0.00010554010805208236}, 'confidence': 0.0001897053443826735, 'similarity': 1.0, 'sentence_len': 10}, {'error_position': 6, 'original': '之', 'corrected_to': '非', 'candidates': {'尤': 0.38277190923690796, '非': 0.17129772901535034, '极': 0.13685572147369385, '十': 0.11843526363372803, '相': 0.024108897894620895}, 'confidence': 0.17129772901535034, 'similarity': 0.5666666666666668, 'sentence_len': 10}]}


{'error_position': 4, 'original': '储', 'corrected_to': '儲', 'candidates': {'储': 0.9982870221138, '儲': 0.0001897053443826735, '贮': 0.00012521656753960997, '库': 0.00011806152906501666, '保': 0.00010554010805208236}, 'confidence': 0.0001897053443826735, 'similarity': 1.0, 'sentence_len': 10}
{'error_position': 6, 'original': '之', 'corrected_to': '非', 'candidates': {'尤': 0.38277190923690796, '非': 0.17129772901535034, '极': 0.13685572147369385, '十': 0.11843526363372803, '相': 0.024108897894620895}, 'confidence': 0.17129772901535034, 'similarity': 0.5666666666666668, 'sentence_len': 10}
```
进一步分析错误位置和候选：
```python
import json
with open("results_0.json", 'r') as f:
    temp = json.loads(f.read())
    
    for item in temp[5:]:

        original_sentence = item['original_sentence']
        corrected_sentence = item['corrected_sentence']        
        num_errors = item['num_errors']        
        errors = item['errors']
        error_position = []
        cand_list = []
        for item in errors:
            error_position.append(item['error_position'])
            cand_list.append(list(item['candidates'].keys()))
        
        error_words = [original_sentence[index] for index in error_position]
        print(original_sentence)
        print('error_words',error_words)
        print(error_position)
        print(cand_list)
        break
```
```python
因此土地储备之观重要
error_words ['储', '之']
[4, 6]
[['储', '儲', '贮', '库', '保'], ['尤', '非', '极', '十', '相']]
```

构建所有候选的句子：
```python
a = [1,2]
b = [4,5]
c = [6,7]
d = [8,9]

from itertools import product
loop_val = [a,b,c,d]

print(*loop_val)

for i in product(*loop_val):
    print(i)
```
## kenlm的完全流程
```python
#进一步分析错误位置和候选：
import json
from itertools import product
import jieba.posseg as pseg
from tqdm import tqdm
import kenlm
import datetime

starttime = datetime.datetime.now()

model = kenlm.LanguageModel('lm.bin')

final_corr_sentences = []
with open("results_0.json", 'r',encoding='utf-8') as f:
    temp = json.loads(f.read())
   
    for item in tqdm(temp):

        original_sentence = item['original_sentence']
        corrected_sentence = item['corrected_sentence']       
        num_errors = item['num_errors']       
        errors = item['errors']
        
        error_position = []
        cand_list = []
        for item in errors:
            if item['original'] == item['corrected_to']:
                #print('continue')
                continue
            error_position.append(item['error_position'])
            cand_list.append(list(item['candidates'].keys()))
        
        ##错字数目，决定是否使用kenlm
        if len(error_position)>2:
#             print(corrected_sentence)
            final_corr_sentences.append(corrected_sentence)
            continue
        
        #生成候选字
        loop_val = cand_list
        error_words = [original_sentence[index] for index in error_position]
        cand_sentences = [original_sentence]*(5**num_errors+1) 
        loop_val = cand_list
        #生成候选句子
        try:
            for index,item in enumerate(product(*loop_val)):
                for i in range(len(error_position)):
                    
                    cand_sentences[index] = cand_sentences[index].replace(cand_sentences[index][error_position[i]],item[i])
        except Exception as e:
            print(e)
            print(i)
            print(sentence)
            print(num_errors)
        score = -9999
        pointer_sentence = ''

        for sentence in cand_sentences:
            ## jieba 分词
            words = pseg.cut(sentence)
            cut_sentence = ''
            
            for word, flag in words:
                cut_sentence=cut_sentence+word+'/'+flag+' '
            ## 使用kenlm计算得分
            if score<model.score(cut_sentence, bos=False, eos=False):
                score = model.score(cut_sentence, bos=False, eos=False)
                pointer_sentence = sentence
        final_corr_sentences.append(pointer_sentence)


endtime = datetime.datetime.now()
print(endtime - starttime)
```

## 对比kenlm+bert 与 only bert效果： 1w step
```
kenlm+bert

检错率： 0.6180292891087188 检错字数: 12745

过纠率： 0.007893857681477592 过纠字数: 827

纠错率： 0.21452817379497624 纠错字数: 4424


only bert

检错率： 0.6271457666569683 检错字数: 12933
    
过纠率： 0.007397508709969932 过纠字数: 775
    
纠错率： 0.24711473183978275 纠错字数: 5096
```

这里出现一个问题，1,2个字的错误，bert能很好的纠错，而错误多了，N-gram的组合数目太多，整个句子的分也难打分。

回到我们之前的想法，对于单个字，定位到那个词，取N=1滑动窗口（N为kenlm模型的N-gram大小），对这样一个组合打分取这个候选字，就不存在组合的关系了。



## kenlm + bert 分析
由于iqiyi的faspell论文阐述道：传统的基于混淆词典的方法，灵活性低，由于混淆词典存在收录不完全，使得召回率变低，如果扩大混淆词典，精确度又不会降低，所以论文的贡献在于使用Bert模型，根据上下文动态生成候选混淆字。其中一个比较重要的点是：传统做法，将混淆词典中的所有候选，无差别对待，直接根据N-gram语言模型，基于统计概率对错字进行纠正，这类似于一刀切的做法，在深度学习基于上下文纠错字符方法的面前相形见绌。

调试好kenlm模型，测了单个句子，发现效果还可以，但是在测全部句子的时候，模型明显引入了更多的错误，究其原因，还是在于当统计数据与文中错误一致的时候，统计概率最大的推断结果才有意义，而通常，N-gram的统计推断受限于窗口大小，并且如上面所说，N-gram模型对所有候选无差别对待，效果好坏取决于模型训练采用的数据集。



在faspell中，拿到这些根据上下文推断出的混淆字后，从候选字的confidence 和 similarity我们可以进一步做文章。当confidence 和 similarity都很高的时候，没必要再进行N-gram纠错，这是显而易见的。 当confidence较低，可以加权similarity 和 N-gram模型的结果。具体的需要调试分析N-gram模型得出的score 和 similarity 的占比关系。

除此之外，我们整句用kenlm，在多个位置候选字进行组合的时候，单句跑的次数呈指数增长，所以，我们只看错字的那个词窗口，这样将指数关系降低为倍数关系。而且单个窗口的计算效率会提高很多。


## 论文分享

爱奇艺 Faspell




## 核心
- A Fast, Adaptable, Simple, Powerful Chinese Spell Checker Based On DAE-Decoder Paradigm

- FASPell based on a new paradigm which consists of a denoising autoencoder (DAE) and a decoder. 

在引入中，可以大致了解到，中文拼写纠错不能很好的使用已有的英文纠错方法：

原因是汉字不像英文句子，自带分词，有各种形态变换，并且汉字的语义信息高度依赖于上下文。

## 目前的瓶颈：

1. 纠错需要的数据量不足，导致模型过拟合。
（A Hybrid Approach to Automatic Corpus Generationfor Chinese Spelling Check） 

腾讯出的文章，即通过生成的方式增加数据量。具体是用OCR和ASR模型，得到识别后的错误数据。这只能视作一种增加数据实用方法。

2. 在利用字符相似度时，缺乏灵活性和混淆性。
inflexibility： 一个字在不同的场景有不同的候选，而候选字多了会影响精度，候选字少了会影响召回。（bert的pretraining，建立Mask概率和错字映射关系，解决这个问题）

insufficiency：字符相似度通过确定一个阈值，产生候选混淆集，候选集中相似的字被统一处理，而字的相似度差异没有充分使用。


DAE+decoder采用seq2seq范式，与Enc-Dec类似：

Enc-Dec中，编码器提取语义信息，解码器生成体现该信息的文本。

DAE+decoder模型中，DAE根据上下文特征从被破坏的文本中重建文本，以提供候选文本，decoder通过合并其他特征来选择最佳候选文本。

## 主要贡献：

- 提出了一种比Liu等人(2010)和Wang等人提出的更精确的字符相似度量化方法。

- 提出了一个经验有效的解码器，过滤候选字符，以获得尽可能高的精度而减少影响召回。
    - 高精度，通常需要较少的候选且候选中有正确的字； 高召回通常需要更多的候选字以覆盖正确的字；
    - 提高精度而减少影响召回，这就要求候选字符覆盖面要少而精。（模型中，根据top-k保证候选字符的召回，根据filter保证候选字符的精度）

## Title: FASP的含义

Fast: 模型很快。它显示无论是在绝对时间消耗还是时间复杂度上，速度都要快于以往最先进的模型。

Adaptable： 模型适应性强。繁简体正确识别，OCR, ASR，CFL外语学习者拼写查错。我们所知,所有先前的最先进的模型只关注繁体中国文字。

Simple: 仅由Mask model 和 filter组成，而不是多个模型融合。

Powerful: 与sota近似的F1，以及在iqiyi ocr数据上的（78.5% in detection and 73.4% in correction)




## 具体模块：

对预训练模型进行微调：

在google bert-zh模型的基础上，构建tfrecode数据，进行run_pretraining，对模型进行finetune预训练？

具体的，统计语音识别错字和对应的最高错误映射字建立probabilites.sav文件，文件的内容如下：
```
1248 秒 0.05263157894736842
1249 柳 0.043478260869565216
1250 草 0.0196078431372549
1251 纯 0.09090909090909091
1252 灵 0.75
1253 狱 0.2222222222222222
1254 途 0.03225806451612903
```

构建tfrecord数据，Mask概率调整:
- 正确句子采用bert的8,1,1（【mask】,random-replace,keep-origin）
- 错误句子根据probabilites.sav，来确定某个字被Mask的概率，而错误句子中的错字是100%被mask的，从而建立了错字和对应正确字的映射关系。为了防止过拟合，错误句子和正确句子数目一样多，正确句子中的对应错误句子中的某个字，还是按正常的mask还原该字，从而防止了映射的过拟合。

tfrecord数据形式：
```

```



Mask Language Model 具体掩码每个位置，通过上下文预测该位置的字，生成候选top-k。


## ocr纠错：ocr通过偏旁拆解，根据笔画元素的编辑距离计算形近度。

## asr纠错: 根据拼音编辑距离计算发音相似度。

## Confidence-Similarity Decoder

在以往的许多模型中，候选过滤器都是为候选字符的多个特征设置不同的阈值和权重。

faspell采用了新的方案，原则是获得尽可能高的精确度和最小的召回损失，具体包括：

若候选top1与原字相同，则视为正确，不进行纠错。

对于候选top1与原字不同的情况，对所有候选字符作以confidence和simliarity的散点图，确定过滤曲线。

由于Bert对候选top-k的概率值变化幅度比较大，所以CSD根据候选的排名设置了对应的rank过滤曲线。由此，我们可以为不同rank的候选，配置不同的过滤曲线。这样保证了候选集中，候选字的差异化对待，避免了传统方法中，候选集字符的无差别计算perplexity的弊端。

（多轮纠错中，引入N-gram, 对比N-gram模型跑出来的候选top1与 bert候选top1的概率，根据概率确定使用哪个更合理）

1. 图为个字候选的散点图
2. 图为优化检错的散点图
3. 图为优化检错和纠错的散点图
4. 图为优化检错和纠错，且设定阈值的的散点图

多轮纠错，每轮只对confidence最高的一个进行纠错。所以，

国 际 电 台 苦(著) 名 丰（主） 持 人 这个例子中，知名的知在candidate中排名最高，但是并不是最终的correction字符。因为先对丰纠错为主，在主持人这个背景下，更常用的搭配是著名。


关于模型的训练：

由于Bert训练的时候，所有句子都是正确的，所以faspell在构建tfrecord的过程中，使用了新的方式，对正确句子仍然采用8,1,1的MASK。而对错误句子，对句子中的错误字，100%MASK，对应label为正确的字，其它字按probability.sav文件概率进行MASK。

具体的，错字数为3的句子，生成错误数+1个句子，正确句子4个，错误句子4个，一共8个。

Aishell共7176条数据，错字在20000左右，生成了

我们在构建语料的时候，需要寻找那种错误字数在20%左右的数据，错误太多，说明语音识别模型精度还不够高，错误太少，构建的样本也就太少。ASRT 80%的准确率就很适合，目前只是在AI-SHELL文件上进行了测试。


数据增强： 错误字数

repeat_make_corrections， 根据num，在最后一轮完成所有纠错。




## Bert张量变换具体细节


### gather_indexes 函数
```python
    @staticmethod
    def gather_indexes(sequence_tensor, positions):

        """Gathers the vectors at the specific positions over a minibatch.
        代码是得到只被masked位置的单词
        for examples:

        flat_offsets = [[0],[10],[20]]
        positions = [[0,1],[2,3],[3,4]]
        flat_positions = [[0,1,12,13,23,24]]
        """
        sequence_shape = modeling.get_shape_list(sequence_tensor, expected_rank=3)
        batch_size = sequence_shape[0]
        seq_length = sequence_shape[1]
        width = sequence_shape[2]

        flat_offsets = tf.reshape(
            tf.range(0, batch_size, dtype=tf.int32) * seq_length, [-1, 1])
        flat_positions = tf.reshape(positions + flat_offsets, [-1])
        flat_sequence_tensor = tf.reshape(sequence_tensor,
                                          [batch_size * seq_length, width])
        output_tensor = tf.gather(flat_sequence_tensor, flat_positions)
        return output_tensor

```



## 具体测试要求

1. 语音识别句子长度要与正确文本长度一致，否则对应位置将错位，根据错误位置监测将出现问题。对应长度不同的数据，将跳过测试。
2. 语音识别精度应该保证在80%左右，太低会导致纠错难度太大。





具体流程：

语音识别后的数据格式为： 正确句子 \t 错误句子； 
经过处理生成了 Create_data所需要的格式：  error_num, 错误句子， 正确句子



## 本周工作：
- 对iqiyi的faspell模型作进一步分析，探究多轮纠错效果。
- 尝试引入N-gram模型，对现有深度学习模型进行调优，测试效果一般，耗时较高，暂时搁置。
- 总结Faspell论文，准备资料开展下周的研讨会。
- 增加预训练模型的数据，测试模型的效果。
- 整理数据分析的文件，简化流程。


## 多轮纠错

将test文件整理为  num,wrong,correct的格式， 且wrong和correct长度要一致，7176条数据就变成6182条，减少了996条数据。

在进行precision和recall计算的时候，先将 correct, wrong, predict文本并排，

1. c!=p, 计算误纠个数wrong_num

2. 根据 w!=p，计算总共纠的个数corrected_num
    - 在w!=p的前提下，计算p==c的个数，作为   TC

    - 在w!=p的前提下，计算c!=w的个数，作为   TD

3. c != w, 计算original_wrong_num作为所有需要纠错的字数。

    
precision = TC/correcteds_num

recall = TC/ original_wrong_num

以及检错的 TD/correcteds_num; TD/original_wrong_num

```python
def test_unit(res, test_path, out_name, strict=True):
    out = open(f'{out_name}.txt', 'w', encoding='utf-8')

    corrected_char = 0
    wrong_char = 0
    corrected_sent = 0
    wrong_sent = 0
    true_corrected_char = 0
    true_corrected_sent = 0
    true_detected_char = 0
    true_detected_sent = 0
    accurate_detected_sent = 0
    accurate_corrected_sent = 0
    all_sent = 0

    for idx, line in enumerate(open(test_path, 'r', encoding='utf-8')):
        all_sent += 1
        falsely_corrected_char_in_sentence = 0
        falsely_detected_char_in_sentence = 0
        true_corrected_char_in_sentence = 0
        true_detected_char_in_sentence = 0

        num, wrong, correct = line.strip().split('\t')
        predict = res[idx]["corrected_sentence"]

        wrong_num = 0
        corrected_num = 0
        original_wrong_num = 0
        

        for c, w, p in zip(correct, wrong, predict):
            if c != p:
                wrong_num += 1
            if w != p:
                corrected_num += 1
                if c == p:
                    true_corrected_char += 1
                if w != c:
                    true_detected_char += 1
                    true_detected_char_in_sentence += 1
            if c != w:
                original_wrong_num += 1

        out.write('\t'.join([str(original_wrong_num), wrong, correct, predict, str(wrong_num)]) + '\n')
        corrected_char += corrected_num
        wrong_char += original_wrong_num
        if original_wrong_num != 0:
            wrong_sent += 1
        if corrected_num != 0 and wrong_num == 0:
            true_corrected_sent += 1

        if corrected_num != 0:
            corrected_sent += 1

        if strict:
            true_detected_flag = (
                    true_detected_char_in_sentence == original_wrong_num and original_wrong_num != 0 and corrected_num == true_detected_char_in_sentence)
        else:
            true_detected_flag = (corrected_num != 0 and original_wrong_num != 0)
        # if corrected_num != 0 and original_wrong_num != 0:
        if true_detected_flag:
            true_detected_sent += 1
        if correct == predict:
            accurate_corrected_sent += 1
        if correct == predict or true_detected_flag:
            accurate_detected_sent += 1

    print("corretion:")
    print(f'char_p={true_corrected_char}/{corrected_char}')
    print(f'char_r={true_corrected_char}/{wrong_char}')
    print(f'sent_p={true_corrected_sent}/{corrected_sent}')
    print(f'sent_r={true_corrected_sent}/{wrong_sent}')
    print(f'sent_a={accurate_corrected_sent}/{all_sent}')
    print("detection:")
    print(f'char_p={true_detected_char}/{corrected_char}')
    print(f'char_r={true_detected_char}/{wrong_char}')
    print(f'sent_p={true_detected_sent}/{corrected_sent}')
    print(f'sent_r={true_detected_sent}/{wrong_sent}')
    print(f'sent_a={accurate_detected_sent}/{all_sent}')

    w = open(f'{out_name}.json', 'w', encoding='utf-8')
    w.write(json.dumps(res, ensure_ascii=False, indent=4, sort_keys=False))
    w.close()
```

## 解决round=n，纠错受限的问题：

通过将最后一次循环的
```python
        for index_control in range(num):
            if index_control != num - 1:

                results = self.make_corrections(sentences_to_be_corrected,
                                                is_train=is_train,
                                                train_on_difference=train_on_difference)
            else:
                results = self.make_corrections(sentences_to_be_corrected,
                                                is_train=is_train,
                                                train_on_difference=train_on_difference,
                                                tackle_n_gram_bias=False)
```


```python
performance of round 0:
corretion:
char_p=4356/10102= 0.43120174222926155
char_r=4356/20622=0.21123072446901367
sent_p=670/5150=0.13009708737864079
sent_r=670/5488=0.12208454810495627
sent_a=1345/6182=0.21756713037851827
detection:
char_p=9392/10102=0.9297168877450009
char_r=9392/20622=0.455435942197653
sent_p=1124/5150=0.21825242718446602
sent_r=1124/5488=0.20481049562682216
sent_a=1799/6182=0.291006146878033
performance of round 1:
corretion:
char_p=5394/14049= 0.3839419175742046
char_r=5394/20622=0.26156531859179516
sent_p=928/5150=0.18019417475728156
sent_r=928/5488=0.16909620991253643
sent_a=1603/6182=0.2593011970236169
detection:
char_p=12920/14049=0.9196384084276461
char_r=12920/20622=0.6265153719328872
sent_p=1936/5150=0.37592233009708736
sent_r=1936/5488=0.35276967930029157
sent_a=2611/6182=0.42235522484632804
performance of round 2:
corretion:
char_p=5556/14990= 0.37064709806537693
char_r=5556/20622=0.26942100669188246
sent_p=961/5150=0.1866019417475728
sent_r=961/5488=0.17510932944606414
sent_a=1636/6182=0.2646392753154319
detection:
char_p=13716/14990=0.9150100066711141
char_r=13716/20622=0.6651149258073902
sent_p=2084/5150=0.4046601941747573
sent_r=2084/5488=0.37973760932944606
sent_a=2759/6182=0.4462956971853769
In 5036 falsely corrected characters, 3673 are because of absent correct candidates.
In 710 falsely detected characters, 288 are because of absent correct candidates.

```

调整训练后的结果：

```
corretion:
char_p=6904/15316= 0.4507704361452076
char_r=6904/20622=0.33478809038890506
sent_p=996/5225=0.190622009569378
sent_r=996/5488=0.1814868804664723
sent_a=1669/6182=0.26997735360724684

detection:
char_p=13828/15316=0.9028466962653434
char_r=13828/20622=0.6705460188148579
sent_p=1962/5225=0.3755023923444976
sent_r=1962/5488=0.35750728862973763
sent_a=2635/6182=0.42623746360401166
In 6924 falsely corrected characters, 4988 are because of absent correct candidates.
In 1488 falsely detected characters, 442 are because of absent correct candidates.
```

## 服务器测试


```python
Bert origin:

6182it [01:06, 93.33it/s]
Elapsed time: 0.0 min 35.18291735649109 s in generating candidates for 6182 sentences;
              65.6057231426239 s in filtering candidates for 6173 sentences;
Speed: 5.691186890406193 ms/sentence in generating and 10.627850824983623 ms/sentence in filtering
performance of round 0:
corretion:
char_p=2688/4960= 0.5419354838709678
char_r=2688/20622=0.13034623217922606
sent_p=513/3485=0.1472022955523673
sent_r=513/5488=0.09347667638483965
sent_a=1201/6182=0.1942736978324167
detection:
char_p=4780/4960=0.9637096774193549
char_r=4780/20622=0.23179129085442732
sent_p=743/3485=0.21319942611190817
sent_r=743/5488=0.13538629737609328
sent_a=1431/6182=0.2314784859268845
In 2092 falsely corrected characters, 1637 are because of absent correct candidates.
In 180 falsely detected characters, 127 are because of absent correct candidates.


```python
候选非top1, flag=True

6182it [01:23, 74.30it/s]
Elapsed time: 0.0 min 35.73702383041382 s in generating candidates for 6182 sentences;
              81.64164137840271 s in filtering candidates for 6173 sentences;
Speed: 5.780819124945619 ms/sentence in generating and 13.22560203764826 ms/sentence in filtering
performance of round 0:
corretion:
char_p=6907/15313= 0.45105465943969175  --  7078/14467= 0.4892513997373332
char_r=6907/20622=0.33493356609446223  --  7078/20622=0.34322568131122105
sent_p=998/5224=0.19104134762633998  --  1029/5180=0.19864864864864865
sent_r=998/5488=0.18185131195335277  --  1029/5488=0.1875
sent_a=1671/6182=0.27030087350372045  --  1703/6182=0.27547719184729863
detection:
char_p=13828/15313=0.9030235747404166  --  13124/14467=0.9071680376028202
char_r=13828/20622=0.6705460188148579  --  13124/20622=0.6364077199107749
sent_p=1964/5224=0.3759571209800919  --  1861/5180=0.3592664092664093
sent_r=1964/5488=0.35787172011661805  --  1861/5488=0.33910349854227406
sent_a=2637/6182=0.42656098350048527  --  2535/6182=0.41006146878033
In 6921 falsely corrected characters, 4987 are because of absent correct candidates.
In 1485 falsely detected characters, 442 are because of absent correct candidates.
```


```python
候选top1, flag=2.5 * confidence+5 * similarity-2 > 0


corretion:
char_p=7078/14467= 0.4892513997373332
char_r=7078/20622=0.34322568131122105
sent_p=1029/5180=0.19864864864864865
sent_r=1029/5488=0.1875
sent_a=1703/6182=0.27547719184729863
detection:
char_p=13124/14467=0.9071680376028202
char_r=13124/20622=0.6364077199107749
sent_p=1861/5180=0.3592664092664093
sent_r=1861/5488=0.33910349854227406
sent_a=2535/6182=0.41006146878033
```