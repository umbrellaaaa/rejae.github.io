---
layout:     post
title:      workday17
subtitle:   
date:       2020-1-8
author:     RJ
header-img: 
catalog: true
tags:
    - job

---
<p id = "build"></p>
---

## 前言
今天学校有个会议要开，同学顺便也一起聚个餐。

下午回来接着做手里的事情。

## 今日工作安排

1. 分析char_meta.txt构建方法，查看CSD对此文件对应的操作，以更改相关结构
2. 简单分析modeling.py文件
3. 寻找音近字混淆词表



## Pre-training with BERT

We are releasing code to do "masked LM" and "next sentence prediction" on an arbitrary text corpus. Note that this is not the exact code that was used for the paper (the original code was written in C++, and had some additional complexity), but this code does generate pre-training data as described in the paper.

Here's how to run the data generation. The input is a plain text file, with one sentence per line. (It is important that these be actual sentences for the "next sentence prediction" task). Documents are delimited by empty lines. The output is a set of tf.train.Examples serialized into TFRecord file format.

You can perform sentence segmentation with an off-the-shelf NLP toolkit such as spaCy. The create_pretraining_data.py script will concatenate segments until they reach the maximum sequence length to minimize computational waste from padding (see the script for more details). However, you may want to intentionally add a slight amount of noise to your input data (e.g., randomly truncate 2% of input segments) to make it more robust to non-sentential input during fine-tuning.

This script stores all of the examples for the entire input file in memory, so for large data files you should shard the input file and call the script multiple times. (You can pass in a file glob to run_pretraining.py, e.g., tf_examples.tf_record*.)

The max_predictions_per_seq is the maximum number of masked LM predictions per sequence. You should set this to around max_seq_length * masked_lm_prob (the script doesn't do that automatically because the exact value needs to be passed to both scripts).

 bert的预训练：输入数据是由一个纯文本文件(文本中每条数据后空一行)经过create_pretraining_data.py（iqiyi是create_tf_record.py）

 对比两个文件：
 
![](https://raw.githubusercontent.com/rejae/rejae.github.io/master/img/
bert_create_data_20200108171806.png)
-----

![](https://raw.githubusercontent.com/rejae/rejae.github.io/master/img/iqiyi_create_data_20200108172027.png)