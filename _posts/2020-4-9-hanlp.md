---
layout:     post
title:      Hanlp
subtitle:   
date:       2020-4-9
author:     RJ
header-img: 
catalog: true
tags:
    - nlp

---
<p id = "build"></p>
---

# 前言
终于用到了hanlp，因为目前这个项目深度学习并不能很好的解决问题。

目前的情感分析是很难做的，因为涉及到立场的问题，虽然句子中有很多负面的情感，比如谴责，坚决反对，控诉，但是是正面的。

- 所以这时候需要我们提取 主谓宾 三元组，根据这三者构建词向量，进行训练和预测。
- 或者我们无法很好的提取到三元组时，我们就提句子的主干，去掉一些影响，比如新闻媒体的词汇会让模型认为他是中性的，也可以降低计算量。

这个时候我们如何提取document中的多个三元组或者主干呢？

可以尝试哈工大的模型：
[实例](https://my.oschina.net/mutoushirana/blog/1841502)

由于是商用，所以虽然效果好，但是还是要另谋他法。

这里采用了Hanlp，为了方便，使用了pyhanlp，但依然安装了JAVA的运行依赖。

## 正文


![](https://raw.githubusercontent.com/rejae/rejae.github.io/master/img/20200410142011.png)

语义分析结果为一个有向无环图，称为语义依存图（Semantic Dependency Graph）。图中的节点为单词，边为语义依存弧，边上的标签为语义关系。

给定一个句子，语义依存分析（Semantic Dependency Parsing，SDP）任务试图找出所有在语义上有所关联的词语对，并且预测相应的语义标签。在中文界，最有影响力的标注方案是BH-SDP，由北京语言大学和哈尔滨工业大学联合制定。在该方案下，一个语义依存分析标注结果如下：

![](https://raw.githubusercontent.com/rejae/rejae.github.io/master/img/006Fmjmcly1fxrqa13iozj30c103h0u0.jpg)

区别于依存句法分析的树形结构：

![](https://raw.githubusercontent.com/rejae/rejae.github.io/master/img/006Fmjmcly1fxrqcvte12j30nq04it9o.jpg)

