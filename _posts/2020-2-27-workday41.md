---
layout:     post
title:      测试模型检错、纠错、错纠率
subtitle:   
date:       2020-2-27
author:     RJ
header-img: 
catalog: true
tags:
    - job

---
<p id = "build"></p>
---

# 系统的测试模型结果
1. ocr
- con-simi-num: flag = 2.5*con + 5*simi > 2
```
ocr 1200
检错率： 0.5594995635728833 检错字数: 11538
过纠率： 0.005192573855772443 过纠字数: 544
纠错率： 0.3614586364077199 纠错字数: 7454
```
- con-simi-num: flag = 2*con + 3*simi > 2
- flag = True

2. asr
- con-simi-num: flag = 2.5*con + 5*simi > 2
```
检错率： 0.6270972747551159 检错字数: 12932
过纠率： 0.007063427671455161 过纠字数: 740
纠错率： 0.3226651149258074 纠错字数: 6654
```
- con-simi-num: flag = 2*con + 3*simi > 2
```
检错率： 0.5236155562021142 检错字数: 10798
过纠率： 0.0054025676514102994 过纠字数: 566
纠错率： 0.32504121811657455 纠错字数: 6703
```
- flag = True
```
检错率： 0.6710794297352343 检错字数: 13839
过纠率： 0.008065670786999475 过纠字数: 845
纠错率： 0.3148094268257201 纠错字数: 6492
```
分析对比可知，完全不过滤候选，flag = True，由bert掩码预测候选top1与原字不同的情况下，检错率最高可达到67.1%，
但是由此会带来较高的过纠率，0.080%，
而纠错率为31.48%.

调节曲线：con-simi-num: flag = 2.5*con + 5*simi > 2，该过滤曲线对候选过滤力度较小，
检错率下降5%个点，过纠率下降到0.070%，纠错率提高1%个点。

调节曲线：con-simi-num: flag = 2*con + 3*simi > 2 ， 高过滤曲线对候选过滤力度较大，
检错率下降15%，过纠率下降到0.054%，但纠错率并没有提升多大，为32.5%


# 测试错纠率和错纠类型
测试数据，发现大量错纠来自于人称。

打开special_filter函数，调试模型。

直接将过滤器设为True, 那么所有候选top1与原字不同都会进入error, 直接根据con和sim联合排序就能得到结果。
```
    {
        "original_sentence": "他有点必理不平衡",
        "corrected_sentence": "她有点心里不平衡",
        "num_errors": 3,
        "errors": [
            {
                "error_position": 0,
                "original": "他",
                "corrected_to": "她",
                "candidates": {
                    "她": 0.9988991022109985,
                    "他": 0.001100251218304038,
                    "它": 5.204749982112844e-07,
                    "我": 7.877685703761017e-08,
                    "ta": 3.7485811787973944e-08
                },
                "confidence": 0.9988991022109985,
                "similarity": 1.0,
                "sentence_len": 8
            },
            {
                "error_position": 3,
                "original": "必",
                "corrected_to": "心",
                "candidates": {
                    "心": 0.9999412298202515,
                    "内": 2.214550295320805e-05,
                    "手": 7.2119382821256295e-06,
                    "腿": 4.1029379644896835e-06,
                    "觉": 3.470316187303979e-06
                },
                "confidence": 0.9999412298202515,
                "similarity": 0.25,
                "sentence_len": 8
            },
            {
                "error_position": 4,
                "original": "理",
                "corrected_to": "里",
                "candidates": {
                    "里": 0.9301846623420715,
                    "理": 0.06978979706764221,
                    "裡": 1.3313424460648093e-05,
                    "态": 7.683703188376967e-06,
                    "绪": 2.02998398890486e-06
                },
                "confidence": 0.9301846623420715,
                "similarity": 1.0,
                "sentence_len": 8
            }
        ]
    }
```

## 预训练tfrecord文件样本过滤
去掉错字很多的样本（num>5），样本数量由13000下降到11300.




## 使用kenlm



## 对bert result.json文件进行解析 对接kenlm
```python
#进一步分析错误位置和候选：
import json
with open("results_0.json", 'r',encoding='utf-8') as f:
    temp = json.loads(f.read())
   
    for item in temp[3:]:

        original_sentence = item['original_sentence']
        corrected_sentence = item['corrected_sentence']       
        num_errors = item['num_errors']       
        errors = item['errors']
        
        error_position = []
        cand_list = []
        for item in errors:
#             if item['original'] == item['corrected_to']:
#                 print('continue')
#                 continue
            error_position.append(item['error_position'])
            cand_list.append(list(item['candidates'].keys()))
       
        #生成候选字
        loop_val = cand_list
        for index,item in enumerate(product(*loop_val)):
            print(item)
        error_words = [original_sentence[index] for index in error_position]
        cand_sentences = [original_sentence]*5**num_errors
        loop_val = cand_list
        #生成候选句子
        for index,item in enumerate(product(*loop_val)):
            for i in range(num_errors):
                cand_sentences[index] = cand_sentences[index].replace(cand_sentences[index][error_position[i]],item[i])
        
        for sentence in cand_sentences:
            print(sentence)
        
        break
        
```